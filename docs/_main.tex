% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{book}
\usepackage{xcolor}
\usepackage[margin=0.79in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{booktabs}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Inserm Workshop 282 - practical session},
  pdfauthor={Benoît Lepage},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Inserm Workshop 282 - practical session}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Mediation analyses with the ltmle and medoutcon packages}
\author{Benoît Lepage}
\date{2025-10-13}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Introduction}\label{introduction}

\begin{figure}

{\centering \includegraphics[width=0.3\linewidth]{./images/url} 

}

\caption{QR code towards the [github repository](https://github.com/chupverse/causal-workshop) of the workshop}\label{fig:qrcode}
\end{figure}

We will use the following \href{https://github.com/benoitlepage/Inserm_workshop_282/blob/main/data/df.csv}{data set}, you can download the data and import it in R.

For example, you can create a R project folder for this practical session, add a ``data'' folder and copy-paste the ``df.csv'' file in the data folder.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Data generating system}\label{data-generating-system}

The data generating mechanism is defined by the following set of structural equations, where:

\begin{itemize}
\tightlist
\item
  baseline confounders are sex (\(L(0)_{sex}\), 0 for women, 1 for men) and low parental education level (\(L(0)_{low.par.edu}\), 0 for no, 1 for yes),
\item
  the exposure of interest is the individual's educational level (\(A_{edu}\), 0 for high, 1 for low),
\item
  2 intermediate confounders affected by the exposure: physical activity (\(L(1)_{phys}\), 0 for no, 1 for yes) and occupation (\(L(1)_{occupation}\), 0 for non-manual, 1 for manual),
\item
  the mediator of interest is smoking (\(M_{smoking}\), 0 for no, 1 for yes),
\item
  the outcome \(Y\) can be death (0 for no, 1 for yes) or a continuous functional score (higher values correspond to higher function).
\end{itemize}

\[
\begin{array}{lll}
  L(0)_{sex}         &=& f\left(U_{sex}\right) \\
  L(0)_{low.par.edu} &=& f\left(L(0)_{sex}, U_{low.par.edu}\right) \\
  A_{edu}            &=& f\left(L(0)_{sex}, L(0)_{low.par.edu}, U_{edu}\right) \\
  L(1)_{phys}        &=& f\left(L(0)_{sex}, L(0)_{low.par.edu}, A_{edu}, U_{L(1)_{phys}}\right) \\
  L(1)_{occupation}  &=& f\left(L(0)_{sex}, L(0)_{low.par.edu}, A_{edu}, L(1)_{phys}, U_{L(1)_{occupation}}\right) \\
  M_{smoking}        &=& f\left(L(0)_{sex}, L(0)_{low.par.edu}, A_{edu}, L(1)_{phys}, L(1)_{occupation}, U_{M_{smoking}}\right) \\
  Y                  &=& f\left(L(0)_{sex}, L(0)_{low.par.edu}, A_{edu}, L(1)_{phys}, L(1)_{occupation}, M_{smoking}, U_Y \right) \\
\end{array}\]

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{./images/DAG_M1} 

}

\caption{Causal model 1}\label{fig:figDAGM1}
\end{figure}

Data were simulated using simple logistic and linear models.

Note that an ``exposure - mediator'' interaction term is included in the equations to simulate the binary and quantitative outcomes. This will have to be considered during the estimations (in case of exposure-mediator interaction, the results will depend on the choice of estimands: pure or total indirect and direct effects).

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The following function can be used to simulate data.frames and estimate}
\DocumentationTok{\#\# the "true" Average total effect and controlled direct effects}
\NormalTok{GenerateData.CDE }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(N, }
                             \AttributeTok{inter =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N), }\CommentTok{\# presence of A*M interaction}
                             \AttributeTok{psi =} \ConstantTok{FALSE}\NormalTok{) \{ }\CommentTok{\# FALSE = simulate data.fame only}
  \DocumentationTok{\#\#\# rexpit function}
\NormalTok{  rexpit }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{ (x) }\FunctionTok{rbinom}\NormalTok{(}\FunctionTok{length}\NormalTok{(x), }\DecValTok{1}\NormalTok{, }\FunctionTok{plogis}\NormalTok{(x))}
  
  \DocumentationTok{\#\#\# baseline confounders L0}
\NormalTok{  sex }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(N, }\AttributeTok{size =} \DecValTok{1}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.45}\NormalTok{) }\CommentTok{\# 0 = women; 1 = men}
\NormalTok{  low\_par\_edu }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex) }\CommentTok{\# low parent education}
  
  \DocumentationTok{\#\#\# exposure A: low educational level = 1}
\NormalTok{  edu }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu)}
\NormalTok{  edu0 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, N)}
\NormalTok{  edu1 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N)}
  
  \DocumentationTok{\#\#\# intermediate counfounders L1}
  \CommentTok{\# physical activity: 1 = yes ; 0 = no}
\NormalTok{  phys }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}
                   \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu)}
\NormalTok{  phys0 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}
                    \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0)}
\NormalTok{  phys1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}
                    \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1)}
  
  \CommentTok{\# occupation: 1 = manual; 0 = non{-}manual}
\NormalTok{  occupation }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.3}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                   \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys) }
\NormalTok{  occupation0 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.3}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys0)  }
\NormalTok{  occupation1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.3}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys1) }
  
  \DocumentationTok{\#\#\# mediator}
\NormalTok{  smoking }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation) }
\NormalTok{  smoking0 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, N)}
\NormalTok{  smoking1 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N)}
\NormalTok{  smoking\_tot0 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                           \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation0) }
\NormalTok{  smoking\_tot1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.3}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                           \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation1) }
                     
  
  \DocumentationTok{\#\#\# outcomes}
\NormalTok{  death }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation }\SpecialCharTok{+} 
                    \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu }\SpecialCharTok{*}\NormalTok{ smoking }\SpecialCharTok{*}\NormalTok{ inter)}
\NormalTok{  death00 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation0 }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{*}\NormalTok{ inter)}
\NormalTok{  death01 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation0 }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{*}\NormalTok{ inter)}
\NormalTok{  death10 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation1 }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{*}\NormalTok{ inter)}
\NormalTok{  death11 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation1 }\SpecialCharTok{+} 
                      \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{*}\NormalTok{ inter)}
\NormalTok{  death\_tot0 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                         \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation0 }\SpecialCharTok{+} 
                         \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking\_tot0 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{*}\NormalTok{ smoking\_tot0 }\SpecialCharTok{*}\NormalTok{ inter)}
\NormalTok{  death\_tot1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                         \FunctionTok{log}\NormalTok{(}\FloatTok{1.7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ occupation1 }\SpecialCharTok{+} 
                         \FunctionTok{log}\NormalTok{(}\FloatTok{2.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ smoking\_tot1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{*}\NormalTok{ smoking\_tot1 }\SpecialCharTok{*}\NormalTok{ inter)}

\NormalTok{  score }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                   \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation }\SpecialCharTok{+} 
                   \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu }\SpecialCharTok{*}\NormalTok{ smoking }\SpecialCharTok{*}\NormalTok{ inter, }
                 \AttributeTok{sd =} \DecValTok{15}\NormalTok{)}
\NormalTok{  score00 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation0 }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{*}\NormalTok{ inter,}
                   \AttributeTok{sd =} \DecValTok{15}\NormalTok{)}
\NormalTok{  score01 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation0 }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{*}\NormalTok{ inter,}
                   \AttributeTok{sd =} \DecValTok{15}\NormalTok{)  }
\NormalTok{  score10 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation1 }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{*}\NormalTok{ smoking0 }\SpecialCharTok{*}\NormalTok{ inter,}
                   \AttributeTok{sd =} \DecValTok{15}\NormalTok{)   }
\NormalTok{  score11 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation1 }\SpecialCharTok{+} 
                     \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{*}\NormalTok{ smoking1 }\SpecialCharTok{*}\NormalTok{ inter, }
                   \AttributeTok{sd =} \DecValTok{15}\NormalTok{)   }
\NormalTok{  score\_tot0 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                        \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys0 }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation0 }\SpecialCharTok{+} 
                        \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking\_tot0 }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu0 }\SpecialCharTok{*}\NormalTok{ smoking\_tot0 }\SpecialCharTok{*}\NormalTok{ inter, }
                      \AttributeTok{sd =} \DecValTok{15}\NormalTok{)}
\NormalTok{  score\_tot1 }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+} \DecValTok{5} \SpecialCharTok{*}\NormalTok{ sex  }\SpecialCharTok{{-}}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ low\_par\_edu }\SpecialCharTok{+} 
                        \SpecialCharTok{{-}}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{+} \DecValTok{8} \SpecialCharTok{*}\NormalTok{ phys1 }\SpecialCharTok{{-}}\DecValTok{7} \SpecialCharTok{*}\NormalTok{ occupation1 }\SpecialCharTok{+} 
                        \SpecialCharTok{{-}}\DecValTok{15} \SpecialCharTok{*}\NormalTok{ smoking\_tot1 }\SpecialCharTok{+} \SpecialCharTok{{-}}\DecValTok{8} \SpecialCharTok{*}\NormalTok{ edu1 }\SpecialCharTok{*}\NormalTok{ smoking\_tot1 }\SpecialCharTok{*}\NormalTok{ inter, }
                      \AttributeTok{sd =} \DecValTok{15}\NormalTok{)}
                   
  
  \ControlFlowTok{if}\NormalTok{ (psi }\SpecialCharTok{==} \ConstantTok{FALSE}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\AttributeTok{data.sim =} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{subjid =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N,}
                                 \AttributeTok{sex =}\NormalTok{ sex, }
                                 \AttributeTok{low\_par\_edu =}\NormalTok{ low\_par\_edu,}
                                 \AttributeTok{edu =}\NormalTok{ edu,}
                                 \AttributeTok{phys =}\NormalTok{ phys,}
                                 \AttributeTok{occupation =}\NormalTok{ occupation,}
                                 \AttributeTok{smoking =}\NormalTok{ smoking,}
                                 \AttributeTok{death =}\NormalTok{ death,}
                                 \AttributeTok{score =}\NormalTok{ score))}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{return}\NormalTok{(}\AttributeTok{Psi =} \FunctionTok{list}\NormalTok{(}\AttributeTok{EY00\_death =} \FunctionTok{mean}\NormalTok{(death00),}
                      \AttributeTok{EY01\_death =} \FunctionTok{mean}\NormalTok{(death01),}
                      \AttributeTok{EY10\_death =} \FunctionTok{mean}\NormalTok{(death10),}
                      \AttributeTok{EY11\_death =} \FunctionTok{mean}\NormalTok{(death11),}
                      \AttributeTok{EY0\_death =} \FunctionTok{mean}\NormalTok{(death\_tot0), }
                      \AttributeTok{EY1\_death =} \FunctionTok{mean}\NormalTok{(death\_tot1),}
                      \AttributeTok{ATE\_death =} \FunctionTok{mean}\NormalTok{(death\_tot1) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(death\_tot0),}
                      \AttributeTok{CDE0\_death =} \FunctionTok{mean}\NormalTok{(death10) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(death00),}
                      \AttributeTok{CDE1\_death =} \FunctionTok{mean}\NormalTok{(death11) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(death01),}
                      \AttributeTok{EY00\_score =} \FunctionTok{mean}\NormalTok{(score00),}
                      \AttributeTok{EY01\_score =} \FunctionTok{mean}\NormalTok{(score01),}
                      \AttributeTok{EY10\_score =} \FunctionTok{mean}\NormalTok{(score10),}
                      \AttributeTok{EY11\_score =} \FunctionTok{mean}\NormalTok{(score11),}
                      \AttributeTok{EY0\_score =} \FunctionTok{mean}\NormalTok{(score\_tot0),}
                      \AttributeTok{EY1\_score =} \FunctionTok{mean}\NormalTok{(score\_tot1),}
                      \AttributeTok{ATE\_score =} \FunctionTok{mean}\NormalTok{(score\_tot1) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(score\_tot0),}
                      \AttributeTok{CDE0\_score =} \FunctionTok{mean}\NormalTok{(score10) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(score00),}
                      \AttributeTok{CDE1\_score =} \FunctionTok{mean}\NormalTok{(score11) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(score01)))}
\NormalTok{  \}}
\NormalTok{\}}


\DocumentationTok{\#\# Simulate the data.frame df }
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{GenerateData.CDE}\NormalTok{(}\AttributeTok{N =} \DecValTok{10000}\NormalTok{, }\AttributeTok{inter =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10000}\NormalTok{), }\AttributeTok{psi =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      subjid           sex          low_par_edu          edu        
##  Min.   :    1   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.: 2501   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median : 5000   Median :0.0000   Median :1.0000   Median :1.0000  
##  Mean   : 5000   Mean   :0.4488   Mean   :0.7329   Mean   :0.5953  
##  3rd Qu.: 7500   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :10000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  
##       phys          occupation       smoking           death       
##  Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  
##  1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:0.0000  
##  Median :1.0000   Median :1.000   Median :1.0000   Median :0.0000  
##  Mean   :0.5579   Mean   :0.744   Mean   :0.5842   Mean   :0.2561  
##  3rd Qu.:1.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  
##  Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  
##      score       
##  Min.   :-49.40  
##  1st Qu.: 15.18  
##  Median : 30.37  
##  Mean   : 30.48  
##  3rd Qu.: 45.67  
##  Max.   : 97.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Calculate the "true" estimands for:}
\DocumentationTok{\#\#  {-} the Average total effect: ATE = E(Y\_0) {-} E(Y\_1)}
\DocumentationTok{\#\#  {-} the controlled direct effect CDE(M=m), setting the mediator to M=m}
\DocumentationTok{\#\#    CDE(M=0) = E(Y\_10) {-} E(Y\_00)}
\DocumentationTok{\#\#    CDE(M=1) = E(Y\_11) {-} E(Y\_01)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{true }\OtherTok{\textless{}{-}} \FunctionTok{GenerateData.CDE}\NormalTok{(}\AttributeTok{N =} \DecValTok{10000}\NormalTok{, }\AttributeTok{inter =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FloatTok{1e6}\NormalTok{), }\AttributeTok{psi =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# CHANGE N TO 1e6 ++++++++++}
\NormalTok{true}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $EY00_death
## [1] 0.096781
## 
## $EY01_death
## [1] 0.209633
## 
## $EY10_death
## [1] 0.163479
## 
## $EY11_death
## [1] 0.416236
## 
## $EY0_death
## [1] 0.153527
## 
## $EY1_death
## [1] 0.332711
## 
## $ATE_death
## [1] 0.179184
## 
## $CDE0_death
## [1] 0.066698
## 
## $CDE1_death
## [1] 0.206603
## 
## $EY00_score
## [1] 48.78223
## 
## $EY01_score
## [1] 33.57381
## 
## $EY10_score
## [1] 36.85815
## 
## $EY11_score
## [1] 13.95586
## 
## $EY0_score
## [1] 41.77577
## 
## $EY1_score
## [1] 21.84661
## 
## $ATE_score
## [1] -19.92916
## 
## $CDE0_score
## [1] -11.92408
## 
## $CDE1_score
## [1] -19.61794
\end{verbatim}

\chapter{Reminders - Estimate the ATE}\label{reminders---estimate-the-ate}

\section{Estimation of the Average Total Effect (ATE) by g-computation}\label{estimation-of-the-average-total-effect-ate-by-g-computation}

G-computation can be used for the estimation of the total effect and two-way decomposition (CDE, randomized direct and indirect effects). Analogs of the 3-way and 4-way decompositions are also given by the \texttt{CMAverse} package.

The following steps describe the implementation of the g-computation estimator of the average total effect \(\text{ATE} = \mathbb{E}(Y_{A=1}) - \mathbb{E}(Y_{A=0})\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\item
  The g-formula for the ATE is :
  \[\small \Psi^{\text{ATE}} =\sum_{l(0) \in L(0)} \mathbb{E}\left(Y \mid A=1, L(0)=l(0)\right)P(L(0) = l(0)) - \sum_{l(0) \in L(0)} \mathbb{E}\left(Y \mid A=0, L(0)=l(0)\right)P(L(0) = l(0))\]
  \[\small \Psi^{\text{ATE}} =\sum_{l(0) \in L(0)} \overline{Q}(A=0) \times P(L(0) = l(0)) - \sum_{l(0) \in L(0)} \overline{Q}(A=1) \times P(L(0) = l(0))\]
\item
  Fit a logistic or a linear regression to estimate \(\overline{Q} = \mathbb{E}(Y \mid A, L(0))\)
\item
  Use this estimate to predict an outcome for each subject \(\hat{\overline{Q}}(A=0)_i\) and \(\hat{\overline{Q}}(A=1)_i\), by evaluating the regression fit \(\overline{Q}\) at \(A=0\) and \(A=1\) respectively
\item
  Plug the predicted outcomes in the g-formula and use the sample mean to estimate \(\Psi_{ATE}\).
\end{enumerate}

We can estimate its components and plug them directly in the g-formula:
\begin{equation}
\hat{\Psi}^{\text{ATE}}_{\text{gcomp}} = \frac{1}{n} \sum_{i=1}^n \left[ \hat{\overline{Q}}(A=1)_i - \hat{\overline{Q}}(A=0)_i \right]
\end{equation}

For continuous outcomes, \(\overline{Q}(A=a)\) functions can be estimated using linear regressions. For binary outcomes, they can be estimated using logistic regressions.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 0. Import data}
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\DocumentationTok{\#\# 1. Estimate Qbar  }
\NormalTok{Q\_tot\_death }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu, }
                   \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{Q\_tot\_score }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu, }
                   \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\DocumentationTok{\#\# 2. Predict an outcome for each subject, setting A=0 and A=1}
\CommentTok{\# prepare data sets used to predict the outcome under the counterfactual }
\CommentTok{\# scenarios setting A=0 and A=1}
\NormalTok{data\_Ais1 }\OtherTok{\textless{}{-}}\NormalTok{ data\_Ais0 }\OtherTok{\textless{}{-}}\NormalTok{ df}
\NormalTok{data\_Ais1}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{data\_Ais0}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{0}

\CommentTok{\# predict values}
\NormalTok{Y1\_death\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_death, }\AttributeTok{newdata =}\NormalTok{ data\_Ais1, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{Y0\_death\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_death, }\AttributeTok{newdata =}\NormalTok{ data\_Ais0, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\NormalTok{Y1\_score\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_score, }\AttributeTok{newdata =}\NormalTok{ data\_Ais1, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{Y0\_score\_pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_score, }\AttributeTok{newdata =}\NormalTok{ data\_Ais0, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\DocumentationTok{\#\# 3. Plug the predicted outcome in the gformula and use the sample mean }
\DocumentationTok{\#\#    to estimate the ATE}
\NormalTok{ATE\_death\_gcomp }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Y1\_death\_pred) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y0\_death\_pred)}
\NormalTok{ATE\_death\_gcomp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1867172
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ATE\_score\_gcomp }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Y1\_score\_pred) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Y0\_score\_pred)}
\NormalTok{ATE\_score\_gcomp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -19.75274
\end{verbatim}

A 95\% confidence interval can be estimated applying a bootstrap procedure. An example is given in the following code.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# set seed for reproducibility}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{B }\OtherTok{\textless{}{-}} \DecValTok{10} \CommentTok{\# use a large number here (at least 200 to 1000)}

\DocumentationTok{\#\# we will store estimates from each bootstrap sample in a data.frame:}
\NormalTok{bootstrap\_estimates }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =}\NormalTok{ B, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{))}
\FunctionTok{colnames}\NormalTok{(bootstrap\_estimates) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"boot\_death\_est"}\NormalTok{, }\StringTok{"boot\_score\_est"}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (b }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{B)\{}
  \CommentTok{\# sample the indices 1 to n with replacement}
\NormalTok{  bootIndices }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(df), }\AttributeTok{replace=}\NormalTok{T)}
\NormalTok{  bootData }\OtherTok{\textless{}{-}}\NormalTok{ df[bootIndices,]}

  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{round}\NormalTok{(b}\SpecialCharTok{/}\DecValTok{100}\NormalTok{, }\DecValTok{0}\NormalTok{) }\SpecialCharTok{==}\NormalTok{ b}\SpecialCharTok{/}\DecValTok{100}\NormalTok{ ) }\FunctionTok{print}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"bootstrap number "}\NormalTok{,b))}
  
\NormalTok{  Q\_tot\_death }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu, }
                   \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ bootData)}
\NormalTok{  Q\_tot\_score }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu, }
                   \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ bootData)}

\NormalTok{  boot\_Ais1 }\OtherTok{\textless{}{-}}\NormalTok{ boot\_Ais0 }\OtherTok{\textless{}{-}}\NormalTok{ bootData}
\NormalTok{  boot\_Ais1}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  boot\_Ais0}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{0}

\NormalTok{  Y1\_death\_boot }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_death, }\AttributeTok{newdata =}\NormalTok{ boot\_Ais1, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{  Y0\_death\_boot }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_death, }\AttributeTok{newdata =}\NormalTok{ boot\_Ais0, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\NormalTok{  Y1\_score\_boot }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_score, }\AttributeTok{newdata =}\NormalTok{ boot\_Ais1, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{  Y0\_score\_boot }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_tot\_score, }\AttributeTok{newdata =}\NormalTok{ boot\_Ais0, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\NormalTok{  bootstrap\_estimates[b,}\StringTok{"boot\_death\_est"}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Y1\_death\_boot }\SpecialCharTok{{-}}\NormalTok{ Y0\_death\_boot)}
\NormalTok{  bootstrap\_estimates[b,}\StringTok{"boot\_score\_est"}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Y1\_score\_boot }\SpecialCharTok{{-}}\NormalTok{ Y0\_score\_boot)}
\NormalTok{\}}

\NormalTok{IC95\_ATE\_death }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(ATE\_death\_gcomp }\SpecialCharTok{{-}} 
                      \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(bootstrap\_estimates[,}\StringTok{"boot\_death\_est"}\NormalTok{]),}
\NormalTok{                    ATE\_death\_gcomp }\SpecialCharTok{+} 
                      \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(bootstrap\_estimates[,}\StringTok{"boot\_death\_est"}\NormalTok{]))}
\NormalTok{IC95\_ATE\_death}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1694074 0.2040270
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{IC95\_ATE\_score }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(ATE\_score\_gcomp }\SpecialCharTok{{-}} 
                      \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(bootstrap\_estimates[,}\StringTok{"boot\_score\_est"}\NormalTok{]),}
\NormalTok{                    ATE\_score\_gcomp }\SpecialCharTok{+} 
                      \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{sd}\NormalTok{(bootstrap\_estimates[,}\StringTok{"boot\_score\_est"}\NormalTok{]))}
                    
\NormalTok{IC95\_ATE\_score}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -20.14219 -19.36330
\end{verbatim}

\section{Estimation of the ATE by IPTW}\label{estimation-of-the-ate-by-iptw}

\subsection{``Classic'' Horvitz Thompson estimator}\label{classic-horvitz-thompson-estimator}

If the average total effect (ATE) is identifiable, \(\Psi_{ATE} = \mathbb{E}(Y_{A=1}) - \mathbb{E}(Y_{A=0})\) can be expressed using Inverse probability of treatment weighting (IPTW), denoting \(\mathbb{P}(A=a \mid L(0)) = g(A=a \mid L(0))\):
\begin{equation}
\Psi_{ATE} = \mathbb{E}\left( \frac{\mathbb{I}(A=1)}{g(A=1 \mid L(0))} Y \right) - \mathbb{E}\left( \frac{\mathbb{I}(A=0)}{g(A=0 \mid L(0))} Y \right)
\end{equation}

The following steps describe the implementation of the IPTW estimator

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Estimate the treatment mechanism \(g(A=1 \mid L(0))\)
\item
  Predict each individual's probability of being exposed to her own exposure
\item
  Apply weights corresponding to the inverse of the predicted probability \(w_i = \frac{1}{\hat{g}(A = a_i \mid L(0)_i)}\)
\item
  Use the empirical mean of the weighted outcome \(Y\): \(\hat{\mathbb{E}}(Y_a) = \frac{1}{n} \sum_{i=1}^n \frac{\mathbb{I}(A_i=a)}{\hat{g}(A=a_i \mid L(0)_i)} Y_i\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\DocumentationTok{\#\# 1. Estimate g}
\NormalTok{g\_L }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(edu }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu, }
           \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\DocumentationTok{\#\# 2. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# predict the probabilities P(A0\_PM2.5=1|L(0)) \& P(A0\_PM2.5=0|L(0))}
\NormalTok{pred\_g1\_L }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_L, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_g0\_L }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pred\_g1\_L}
\CommentTok{\# the predicted probability of the observed treatment A=a\_i is :}
\NormalTok{gA\_L }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gA\_L[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ pred\_g1\_L[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]}
\NormalTok{gA\_L[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ pred\_g0\_L[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]}

\DocumentationTok{\#\# 3. Apply weights corresponding to the inverse of the predicted probability}
\NormalTok{wt }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ gA\_L}

\DocumentationTok{\#\# 4. Use the empirical mean of the weighted outcome}
\CommentTok{\# point estimates:}
\NormalTok{IPTW\_death }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death) }\SpecialCharTok{{-}}
  \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death)}
\NormalTok{IPTW\_death}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1865118
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{IPTW\_score }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{score) }\SpecialCharTok{{-}}
  \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{score)}
\NormalTok{IPTW\_score}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -19.76854
\end{verbatim}

The ATE estimates using IPTW for death probability and mean quality of life are respectively +18.65\% and -19.77.

\subsection{Stabilized IPTW for the ATE}\label{stabilized-iptw-for-the-ate}

If the average total effect (ATE) is identifiable, \(\Psi_{ATE}\) can be estimated using a stabilized IPTW estimator:
\begin{equation}
\hat{\mathbb{E}}(Y_1) - \hat{\mathbb{E}}(Y_0) =  \frac{\frac{1}{n} \sum_{i=1}^n \frac{\mathbb{I}(A_i=1)\hat{g}^*(A_i=1)}{\hat{g}(A_i=1 \mid L(0)_i)} Y_i}{ \frac{1}{n} \sum_{i=1}^n \frac{\mathbb{I}(A_i=1)\hat{g}^*(A_i=1)}{\hat{g}(A_i=1 \mid L(0)_i)}} - \frac{\frac{1}{n} \sum_{i=1}^n \frac{\mathbb{I}(A_i=0)\hat{g}^*(A_i=0)}{\hat{g}(A_i=0 \mid L(0)_i)} Y_i}{ \frac{1}{n} \sum_{i=1}^n \frac{\mathbb{I}(A_i=0)\hat{g}^*(A_i=0)}{\hat{g}(A_i=0 \mid L(0)_i)}}
\end{equation}
The estimation algorithm is the same as for IPTW, but taking into account any non-null function of \(A\) (\(g^*(A_i=a)\)) in the denominator of the weight in step 3, and applying the stabilized estimator in step 4.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 3. For example, applying g\^{}*(A) = 1}
\DocumentationTok{\#\# 4. Applying the stabilized estimator}
\CommentTok{\# point estimates:}
\NormalTok{sIPTW\_death }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death) }\SpecialCharTok{/}
                   \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{))) }\SpecialCharTok{{-}}
\NormalTok{  (}\FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death) }\SpecialCharTok{/}
     \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)))}
\NormalTok{sIPTW\_death}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1865687
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sIPTW.score }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{score) }\SpecialCharTok{/}
                 \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{))) }\SpecialCharTok{{-}}
\NormalTok{  (}\FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{score) }\SpecialCharTok{/}
     \FunctionTok{mean}\NormalTok{(wt }\SpecialCharTok{*} \FunctionTok{as.numeric}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)))}
\NormalTok{sIPTW.score}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -19.75943
\end{verbatim}

The ATE estimates using stabilized IPTW for death probability and mean quality of life are respectively +18.66\% and -19.76.

\subsection{Using an MSM estimated by IPTW}\label{using-an-msm-estimated-by-iptw}

We can also express the ATE using coefficients of a MSM. For a continuous or binary outcome, we can use the following MSM to summarize the relationship between the counterfactual outcome (\(Y_a\)) and the exposure(s) \(A\):
\begin{equation} 
  \mathbb{E}(Y_a) = \alpha_0 + \alpha_A a 
  \label{eq:MSMATEmarg}
\end{equation}

The Average Total Effect \(\text{ATE} = \mathbb{E}(Y_{A=1}) - \mathbb{E}(Y_{A=0})\) can then be expressed using the coefficients of this MSM \eqref{eq:MSMATEmarg}:
\begin{equation*} 
  \text{ATE} := \left(\alpha_0 + \alpha_A \times 1 \right) - \left(\alpha_0 + \alpha_A \times 0 \right) = \alpha_A 
\end{equation*}

In this example, the coefficient \(\alpha_A\) corresponds to the \(\text{ATE}\).

Such a model is not very useful for a binary exposure. It would be much more useful for higher-dimensional exposures, for example with a continuous exposure, where the relationship between all the possible continuous values of the exposure \(A=a\) and the corresponding outcomes \(Y_a\) is summarized (and arbitrarily simplified) by a single line and the slope coefficient \(\alpha_A\).

MSM coefficients can be easily estimated using an Inverse Probability of Treatment (IPTW) approach based on weighted regressions.

For example, in order to fit the MSM \eqref{eq:MSMATEmarg} described above, we can use a linear regression of the (observed) outcome \(Y\) on the exposure, weigthed by individual weights \(w_i\) or \(sw_i\):
\begin{equation} 
  \mathbb{E}(Y) = \alpha_0 + \alpha_A a 
\end{equation}

where \(w_i=\frac{1}{P(A=a_i \mid L(0)=l(0)_i)}\) or \(sw_i=\frac{P(A=a_i)}{P(A=a_i \mid L(0)=l(0)_i)}\).

The ``no-unmeasured confounding'' assumption is addressed by the application of weights \(w_i\) or \(sw_i\), which balance confounders \(L(0)\) relative to the exposure \(A\).

Below, we give an example where the parameters of an MSM are estimated using a weighted regression.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\DocumentationTok{\#\# 1. Denominator of the weight}
\CommentTok{\# 1a. Estimate g(A=a\_i|L(0)) (denominator of the weight)}
\NormalTok{g\_A\_L }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(edu }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu,}
             \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\CommentTok{\# 1b. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# predict the probabilities P(edu = 1) \& P(edu = 0)}
\NormalTok{pred\_g1\_L }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_A\_L, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_g0\_L }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pred\_g1\_L}
\CommentTok{\# the predicted probability of the observed treatment P(A = a\_i | L(0)) is :}
\NormalTok{gAi\_L }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gAi\_L[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ pred\_g1\_L[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}
\NormalTok{gAi\_L[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ pred\_g0\_L[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]}

\DocumentationTok{\#\# 2. Numerator of the weight}
\CommentTok{\# The numerator of the weight can be 1 for simple weights,}
\CommentTok{\# or g(A=a\_i|V) to obtain stabilized weights which put less weight to individuals}
\CommentTok{\# with less observation. Stabilized weights enable a weaker positivity assumption.}

\CommentTok{\# 2a. Estimate g(A=a\_i) (numerator of the stabilized weight)}
\NormalTok{g\_A }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(edu }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
           \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\CommentTok{\# 2b. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# predict the probabilities P(edu = 1) \& P(edu = 0)}
\NormalTok{pred\_g1 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_A, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_g0 }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ pred\_g1}
\CommentTok{\# the predicted probability of the observed treatment P(A = a\_i) is :}
\NormalTok{gAi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gAi[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ pred\_g1[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}
\NormalTok{gAi[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ pred\_g0[df}\SpecialCharTok{$}\NormalTok{edu}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]}

\DocumentationTok{\#\# 3. Define individual weights:}
\CommentTok{\# We can use simple weights w = 1 / g(A=a\_i | L(0))}
\NormalTok{w }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ gAi\_L}
\CommentTok{\# Or alternatively, we can use stabilized weights : }
\CommentTok{\# sw = g(A=a\_i | sex) / g(A=a\_i | L(0))}
\NormalTok{sw }\OtherTok{\textless{}{-}}\NormalTok{ gAi }\SpecialCharTok{/}\NormalTok{ gAi\_L}

\CommentTok{\# we can see that stabilized weights have less extreme values}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfcol =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{boxplot}\NormalTok{(w }\SpecialCharTok{\textasciitilde{}}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu)}
\FunctionTok{boxplot}\NormalTok{(sw }\SpecialCharTok{\textasciitilde{}}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{_main_files/figure-latex/Psi_ATE_bysex_MSM-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfcol =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}

\DocumentationTok{\#\# applying these weights creates a pseudo{-}population were the baseline}
\DocumentationTok{\#\# confounders are balanced, relative to the exposure:}
\DocumentationTok{\#\# before applying weights to the individuals:}
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{sex, df}\SpecialCharTok{$}\NormalTok{edu, }\AttributeTok{deparse.level =} \DecValTok{2}\NormalTok{), }
           \AttributeTok{margin =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       df$edu
## df$sex         0         1
##      0 0.5245861 0.5692928
##      1 0.4754139 0.4307072
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{table}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{low\_par\_edu, df}\SpecialCharTok{$}\NormalTok{edu, }\AttributeTok{deparse.level =} \DecValTok{2}\NormalTok{), }
           \AttributeTok{margin =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               df$edu
## df$low_par_edu         0         1
##              0 0.3397578 0.2177054
##              1 0.6602422 0.7822946
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# after applying weights to the individuals:}
\FunctionTok{library}\NormalTok{(questionr) }\CommentTok{\# The questionr package enables to describe weighted populations}
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{wtd.table}\NormalTok{(}\AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{sex, }\AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu, }\AttributeTok{weights =}\NormalTok{ w), }\AttributeTok{margin =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           0         1
## 0 0.5518912 0.5516449
## 1 0.4481088 0.4483551
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.table}\NormalTok{(}\FunctionTok{wtd.table}\NormalTok{(}\AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{low\_par\_edu, }\AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu, }\AttributeTok{weights =}\NormalTok{ w), }\AttributeTok{margin =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           0         1
## 0 0.2668761 0.2669119
## 1 0.7331239 0.7330881
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 4. Estimate coefficients of the MSM using a weighted regression E(Y | A, sex)}
\CommentTok{\# a GLM with gaussian family can be applied to estimate risk differences}
\CommentTok{\# (for relative risk or rate ratios, we can apply a Poisson family; }
\CommentTok{\#  for OR, we can apply a binomial family)}
\NormalTok{msm1 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu,}
           \AttributeTok{weights =}\NormalTok{ w,}
           \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{,}
           \AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{coef}\NormalTok{(msm1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)         edu 
##   0.1441017   0.1865687
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{msm2 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu,}
            \AttributeTok{weights =}\NormalTok{ sw,}
            \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{,}
            \AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{coef}\NormalTok{(msm2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)         edu 
##   0.1441017   0.1865687
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 5. Estimate the ATE stratified by sex}
\CommentTok{\# According to MSM1 (with simple weights)}
\FunctionTok{coef}\NormalTok{(msm1)[}\StringTok{"edu"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       edu 
## 0.1865687
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# According to the MSM2 (with stabilized weights)}
\FunctionTok{coef}\NormalTok{(msm2)[}\StringTok{"edu"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       edu 
## 0.1865687
\end{verbatim}

The ATE estimates of death probability using an MSM estimated by IPTW is +18.65\%.

The results are the same with unstabilized or stabilized weights because there is no violation of the positivity assumption. In case of positivity violation, stabilized weights would give more accurate estimates.

95\% confidence intervals can be calculated by bootstrap.

\chapter{Applying the CMAverse}\label{applying-the-cmaverse}

If we use the \texttt{CMAverse} package with the \texttt{df} data set, we can estimate the Average Total Effect (\(ATE\)) and the Controlled direct effects (setting the mediator to 0) (\(CDE(M=0)\)).

\begin{align*}
ATE &= \mathbb{E}(Y_{A=1}) - \mathbb{E}(Y_{A=0}) \\
CDE(M=0) &= \mathbb{E}(Y_{A=1,M=0}) - \mathbb{E}(Y_{A=0,M=0}) 
\end{align*}

In case of intermediate confounders affected by the exposure, the estimation based on regression coefficients cannot be used to estimate CDE and other direct and indirect effects. We need to use a g-computation, an IPTW estimator or a double-robust estimator.

\section{Estimation by ``parametric'' g-computation}\label{estimation-by-parametric-g-computation}

For example, we can estimate the two estimands ATE and CDE(M=0) on a risk difference scale as described below. In order to get estimates on the risk difference scale, the \texttt{yreg} argument needs to be set to \texttt{"linear"}.

In order to estimate CDE(M=0) by parametric g-computation, we need:

\begin{itemize}
\tightlist
\item
  a model of the outcome (note that the \texttt{exposure*mediator} interaction is correctly included)
\item
  a model of each of the intermediate confounder (2 models in our example).
\end{itemize}

Using those 3 models, we can simulated counterfactual values (under \(\{A=1,M=0\}\) and \(\{A=0,M=0\}\)) exactly as what we did in the introduction chapter to simulate the data set \texttt{df}.

In the results, the model of the mediator is not needed for the CDE, but it is needed to estimate the interventional (stochastic) direct and indirect effects.

Note that for the model of the intermediate confounder \texttt{occupation}, physical activity (\texttt{phys}) was not included as a predictor whereas it was present in the corresponding equation of the data-generating system: Can this ``misspecification'' result in some bias? (I don't know the answer, it might be interesting to test on simulations).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(CMAverse)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{gformula\_death\_RD }\OtherTok{\textless{}{-}} \FunctionTok{cmest}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df, }
                           \AttributeTok{model =} \StringTok{"gformula"}\NormalTok{, }\CommentTok{\# for parametric g{-}computation}
                           \AttributeTok{outcome =} \StringTok{"death"}\NormalTok{, }\CommentTok{\# outcome variable}
                           \AttributeTok{exposure =} \StringTok{"edu"}\NormalTok{, }\CommentTok{\# exposure variable}
                           \AttributeTok{mediator =} \StringTok{"smoking"}\NormalTok{, }\CommentTok{\# mediator}
                           \AttributeTok{basec =} \FunctionTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{,     }
                                     \StringTok{"low\_par\_edu"}\NormalTok{), }\CommentTok{\# baseline confounders}
                           \AttributeTok{postc =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }
                                     \StringTok{"occupation"}\NormalTok{), }\CommentTok{\# intermediate confounders }
                           \AttributeTok{EMint =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# exposures*mediator interaction}
                           \AttributeTok{mreg =} \FunctionTok{list}\NormalTok{(}\StringTok{"logistic"}\NormalTok{), }\CommentTok{\# g(M=1|L1,A,L0)}
                           \AttributeTok{yreg =} \StringTok{"linear"}\NormalTok{,}\CommentTok{\# Qbar.L2 = P(Y=1|M,L1,A,L0) }
                           \AttributeTok{postcreg =} \FunctionTok{list}\NormalTok{(}\StringTok{"logistic"}\NormalTok{, }\StringTok{"logistic"}\NormalTok{), }
                           \AttributeTok{astar =} \DecValTok{0}\NormalTok{,}
                           \AttributeTok{a =} \DecValTok{1}\NormalTok{,}
                           \AttributeTok{mval =} \FunctionTok{list}\NormalTok{(}\DecValTok{0}\NormalTok{), }\CommentTok{\# do(M=0) to estimate CDE(M=0)}
                           \AttributeTok{estimation =} \StringTok{"imputation"}\NormalTok{, }\CommentTok{\# if model= gformula}
                           \AttributeTok{inference =} \StringTok{"bootstrap"}\NormalTok{,}
                           \AttributeTok{boot.ci.type =} \StringTok{"per"}\NormalTok{, }\CommentTok{\# percentiles, other option: "bca"}
                           \AttributeTok{nboot =} \DecValTok{2}\NormalTok{) }\CommentTok{\# use a large number of bootstrap samples}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   |                                                                              |                                                                      |   0%  |                                                                              |===================================                                   |  50%  |                                                                              |======================================================================| 100%
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(gformula\_death\_RD)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Causal Mediation Analysis
## 
## # Outcome regression:
## 
## Call:
## glm(formula = death ~ edu + smoking + edu * smoking + sex + low_par_edu + 
##     phys + occupation, family = gaussian(), data = getCall(x$reg.output$yreg)$data, 
##     weights = getCall(x$reg.output$yreg)$weights)
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -0.0006107  0.0128884  -0.047   0.9622    
## edu          0.0585572  0.0128876   4.544 5.59e-06 ***
## smoking      0.1122164  0.0130604   8.592  < 2e-16 ***
## sex          0.0633703  0.0084086   7.536 5.25e-14 ***
## low_par_edu  0.0652140  0.0094112   6.929 4.49e-12 ***
## phys        -0.0168476  0.0084636  -1.991   0.0466 *  
## occupation   0.0413486  0.0097641   4.235 2.31e-05 ***
## edu:smoking  0.1484815  0.0170875   8.689  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 0.1671299)
## 
##     Null deviance: 1905.1  on 9999  degrees of freedom
## Residual deviance: 1670.0  on 9992  degrees of freedom
## AIC: 10499
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## # Mediator regressions: 
## 
## Call:
## glm(formula = smoking ~ edu + sex + low_par_edu + phys + occupation, 
##     family = binomial(), data = getCall(x$reg.output$mreg[[1L]])$data, 
##     weights = getCall(x$reg.output$mreg[[1L]])$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.85996    0.06143 -13.998   <2e-16 ***
## edu          0.70047    0.04402  15.911   <2e-16 ***
## sex          0.62499    0.04365  14.318   <2e-16 ***
## low_par_edu  0.41552    0.04772   8.707   <2e-16 ***
## phys        -0.38703    0.04418  -8.761   <2e-16 ***
## occupation   0.59325    0.04946  11.993   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13578  on 9999  degrees of freedom
## Residual deviance: 12685  on 9994  degrees of freedom
## AIC: 12697
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## # Regressions for mediator-outcome confounders affected by the exposure: 
## 
## Call:
## glm(formula = phys ~ edu + sex + low_par_edu, family = binomial(), 
##     data = getCall(x$reg.output$postcreg[[1L]])$data, weights = getCall(x$reg.output$postcreg[[1L]])$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.38815    0.04765   8.145 3.78e-16 ***
## edu         -0.34545    0.04205  -8.215  < 2e-16 ***
## sex          0.43714    0.04124  10.599  < 2e-16 ***
## low_par_edu -0.19185    0.04689  -4.092 4.28e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13729  on 9999  degrees of freedom
## Residual deviance: 13519  on 9996  degrees of freedom
## AIC: 13527
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## 
## Call:
## glm(formula = occupation ~ edu + sex + low_par_edu, family = binomial(), 
##     data = getCall(x$reg.output$postcreg[[2L]])$data, weights = getCall(x$reg.output$postcreg[[2L]])$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.37498    0.05083   7.378 1.61e-13 ***
## edu          0.85924    0.04734  18.150  < 2e-16 ***
## sex          0.36173    0.04783   7.562 3.97e-14 ***
## low_par_edu  0.09333    0.05217   1.789   0.0736 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 11377  on 9999  degrees of freedom
## Residual deviance: 10977  on 9996  degrees of freedom
## AIC: 10985
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## # Effect decomposition on the mean difference scale via the g-formula approach
##  
## Direct counterfactual imputation estimation with 
##  bootstrap standard errors, percentile confidence intervals and p-values 
##  
##                Estimate Std.error   95% CIL 95% CIU  P.val    
## cde           0.0715898 0.0102149 0.0648080   0.079 <2e-16 ***
## rpnde         0.1415395 0.0124769 0.1284949   0.145 <2e-16 ***
## rtnde         0.1735670 0.0166478 0.1519051   0.174 <2e-16 ***
## rpnie         0.0242051 0.0002929 0.0222740   0.023 <2e-16 ***
## rtnie         0.0562325 0.0038779 0.0460777   0.051 <2e-16 ***
## te            0.1977720 0.0163549 0.1745726   0.197 <2e-16 ***
## rintref       0.0699497 0.0022620 0.0636869   0.067 <2e-16 ***
## rintmed       0.0320275 0.0041709 0.0234102   0.029 <2e-16 ***
## cde(prop)     0.3619816 0.0210889 0.3711416   0.399 <2e-16 ***
## rintref(prop) 0.3536883 0.0188551 0.3395706   0.365 <2e-16 ***
## rintmed(prop) 0.1619413 0.0100660 0.1340541   0.148 <2e-16 ***
## rpnie(prop)   0.1223887 0.0122998 0.1133772   0.130 <2e-16 ***
## rpm           0.2843301 0.0022338 0.2609549   0.264 <2e-16 ***
## rint          0.5156296 0.0087890 0.4871483   0.499 <2e-16 ***
## rpe           0.6380184 0.0210889 0.6005255   0.629 <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (cde: controlled direct effect; rpnde: randomized analogue of pure natural direct effect; rtnde: randomized analogue of total natural direct effect; rpnie: randomized analogue of pure natural indirect effect; rtnie: randomized analogue of total natural indirect effect; te: total effect; rintref: randomized analogue of reference interaction; rintmed: randomized analogue of mediated interaction; cde(prop): proportion cde; rintref(prop): proportion rintref; rintmed(prop): proportion rintmed; rpnie(prop): proportion rpnie; rpm: randomized analogue of overall proportion mediated; rint: randomized analogue of overall proportion attributable to interaction; rpe: randomized analogue of overall proportion eliminated)
## 
## Relevant variable values: 
## $a
## [1] 1
## 
## $astar
## [1] 0
## 
## $mval
## $mval[[1]]
## [1] 0
\end{verbatim}

The ATE = 0.1978 and the CDE(M=0) = 0.0716.

\section{Estimation by MSM estimated by IPTW}\label{estimation-by-msm-estimated-by-iptw}

The CDE(M=0) can also by estimated using Marginal structural models (MSM) estimated by IPTW.

In order to get estimations by IPTW, the \texttt{model} argument needs to be set to \texttt{msm}.

The \texttt{cmest} function will estimate:

\begin{itemize}
\tightlist
\item
  a MSM for the outcome (depending only on the exposure and the mediator). Confounding is handled by weighting. This MSM can be used to estimate the controlled direct effect.
\end{itemize}

\begin{align*}
    \mathbb{E}(Y_{A=a,M=m}) &= \beta_0 + \beta_{A_{educ}} \times a + \beta_{M_{smoking}} \times m + \beta_{A \star M} \times (a \times m) \\
    CDE(M=m) &= \mathbb{E}(Y_{A=1,M=m}) - \mathbb{E}(Y_{A=0,M=m}) = \beta_{A_{educ}} + \beta_{A \star M} \times m
  \end{align*}

\begin{itemize}
\tightlist
\item
  the weights \(sw = sw_A \times sw_M\) is needed to handle confounding in the MSM of the outcome, where \(sw_A\) is a weight balancing parents of the exposure \(A\) and \(sw_M\) is a weight balancing parents of the mediator. To calculate those weights, we need to specify the numerator and denominator for the mediator's weight with the \texttt{wmnomreg} and \texttt{wmdenomreg} arguments. The denominator for the exposure's weight is specified with the \texttt{ereg} argument.
\end{itemize}

\begin{align*}
    sw = sw_A \times sw_M = \frac{P(A_i)}{P(A_i \mid L(0))} \times \frac{P(M_i \mid A)}{P(M_i \mid L(0),A,L(1))}
  \end{align*}

An MSM of the mediator is also estimated (depending only on the exposure, confounding is handled by weighting). This MSM is not useful to estimate the CDE, but is needed to estimated the ``interventional'' or ``stochastic'' natural direct and indirect effects.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{iptw\_death\_RD }\OtherTok{\textless{}{-}} \FunctionTok{cmest}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df, }
                       \AttributeTok{model =} \StringTok{"msm"}\NormalTok{, }\CommentTok{\# using MSM estimated by IPTW}
                       \AttributeTok{outcome =} \StringTok{"death"}\NormalTok{, }\CommentTok{\# outcome variable}
                       \AttributeTok{exposure =} \StringTok{"edu"}\NormalTok{, }\CommentTok{\# exposure variable}
                       \AttributeTok{mediator =} \StringTok{"smoking"}\NormalTok{, }\CommentTok{\# mediator}
                       \AttributeTok{basec =} \FunctionTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{,     }
                                 \StringTok{"low\_par\_edu"}\NormalTok{), }\CommentTok{\# baseline confounders}
                       \AttributeTok{postc =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }
                                 \StringTok{"occupation"}\NormalTok{), }\CommentTok{\# intermediate confounders }
                       \AttributeTok{EMint =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# exposures*mediator interaction}
                       \AttributeTok{ereg =} \StringTok{"logistic"}\NormalTok{, }\CommentTok{\# exposure regression model g(A=1|L(0))}
                       \AttributeTok{mreg =} \FunctionTok{list}\NormalTok{(}\StringTok{"logistic"}\NormalTok{), }\CommentTok{\# g(M=1|L1,A,L0)}
                       \AttributeTok{yreg =} \StringTok{"linear"}\NormalTok{,}\CommentTok{\# Qbar.L2 = P(Y=1|M,L1,A,L0) }
                       \AttributeTok{postcreg =} \FunctionTok{list}\NormalTok{(}\StringTok{"logistic"}\NormalTok{, }\StringTok{"logistic"}\NormalTok{), }\CommentTok{\# Qbar.L1 = P(L1=1|A,L0)}
                       \AttributeTok{wmnomreg =} \FunctionTok{list}\NormalTok{(}\StringTok{"logistic"}\NormalTok{), }\CommentTok{\#g(M=1|A) wgt nominator}
                       \AttributeTok{wmdenomreg =} \FunctionTok{list}\NormalTok{(}\StringTok{"logistic"}\NormalTok{), }\CommentTok{\# g(M=1|L1,A,L(0)) wgt denominator}
                       \AttributeTok{astar =} \DecValTok{0}\NormalTok{,}
                       \AttributeTok{a =} \DecValTok{1}\NormalTok{,}
                       \AttributeTok{mval =} \FunctionTok{list}\NormalTok{(}\DecValTok{0}\NormalTok{), }\CommentTok{\# do(M=0) to estimate CDE\_m}
                       \AttributeTok{estimation =} \StringTok{"imputation"}\NormalTok{, }\CommentTok{\# if model= gformula}
                       \AttributeTok{inference =} \StringTok{"bootstrap"}\NormalTok{,}
                       \AttributeTok{boot.ci.type =} \StringTok{"per"}\NormalTok{, }\CommentTok{\# for percentile, other option: "bca"}
                       \AttributeTok{nboot =} \DecValTok{2}\NormalTok{) }\CommentTok{\# we should use a large number of bootstrap samples}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   |                                                                              |                                                                      |   0%
\end{verbatim}

\begin{verbatim}
##   |                                                                              |===================================                                   |  50%
\end{verbatim}

\begin{verbatim}
##   |                                                                              |======================================================================| 100%
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(iptw\_death\_RD)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Causal Mediation Analysis
## 
## # Outcome regression:
## 
## Call:
## glm(formula = death ~ edu + smoking + edu * smoking, family = gaussian(), 
##     data = getCall(x$reg.output$yreg)$data, weights = getCall(x$reg.output$yreg)$weights)
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 0.082933   0.008865   9.355  < 2e-16 ***
## edu         0.070447   0.012775   5.514 3.59e-08 ***
## smoking     0.119740   0.012960   9.239  < 2e-16 ***
## edu:smoking 0.142064   0.017184   8.267  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for gaussian family taken to be 0.1690611)
## 
##     Null deviance: 1880.9  on 9999  degrees of freedom
## Residual deviance: 1689.9  on 9996  degrees of freedom
## AIC: 10969
## 
## Number of Fisher Scoring iterations: 2
## 
## 
## # Mediator regressions: 
## 
## Call:
## glm(formula = smoking ~ edu, family = binomial(), data = getCall(x$reg.output$mreg[[1L]])$data, 
##     weights = getCall(x$reg.output$mreg[[1L]])$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.11692    0.03149  -3.713 0.000205 ***
## edu          0.78869    0.04174  18.895  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13576  on 9999  degrees of freedom
## Residual deviance: 13214  on 9998  degrees of freedom
## AIC: 13197
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## # Mediator regressions for weighting (denominator): 
## 
## Call:
## glm(formula = smoking ~ edu + sex + low_par_edu + phys + occupation, 
##     family = binomial(), data = getCall(x$reg.output$wmdenomreg[[1L]])$data, 
##     weights = getCall(x$reg.output$wmdenomreg[[1L]])$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.85996    0.06143 -13.998   <2e-16 ***
## edu          0.70047    0.04402  15.911   <2e-16 ***
## sex          0.62499    0.04365  14.318   <2e-16 ***
## low_par_edu  0.41552    0.04772   8.707   <2e-16 ***
## phys        -0.38703    0.04418  -8.761   <2e-16 ***
## occupation   0.59325    0.04946  11.993   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13578  on 9999  degrees of freedom
## Residual deviance: 12685  on 9994  degrees of freedom
## AIC: 12697
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## # Mediator regressions for weighting (nominator): 
## 
## Call:
## glm(formula = smoking ~ edu, family = binomial(), data = getCall(x$reg.output$wmnomreg[[1L]])$data, 
##     weights = getCall(x$reg.output$wmnomreg[[1L]])$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept) -0.13313    0.03151  -4.225 2.39e-05 ***
## edu          0.81446    0.04178  19.493  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13578  on 9999  degrees of freedom
## Residual deviance: 13192  on 9998  degrees of freedom
## AIC: 13196
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## # Exposure regression for weighting: 
## 
## Call:
## glm(formula = edu ~ sex + low_par_edu, family = binomial(), data = getCall(x$reg.output$ereg)$data, 
##     weights = getCall(x$reg.output$ereg)$weights)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)    
## (Intercept)  0.02910    0.04186   0.695    0.487    
## sex         -0.23178    0.04154  -5.580 2.41e-08 ***
## low_par_edu  0.63793    0.04599  13.871  < 2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 13497  on 9999  degrees of freedom
## Residual deviance: 13285  on 9997  degrees of freedom
## AIC: 13291
## 
## Number of Fisher Scoring iterations: 4
## 
## 
## # Effect decomposition on the mean difference scale via the marginal structural model
##  
## Direct counterfactual imputation estimation with 
##  bootstrap standard errors, percentile confidence intervals and p-values 
##  
##               Estimate Std.error  95% CIL 95% CIU  P.val    
## cde           0.070447  0.007889 0.067239   0.078 <2e-16 ***
## rpnde         0.137886  0.005815 0.137662   0.145 <2e-16 ***
## rtnde         0.164690  0.003025 0.168127   0.172 <2e-16 ***
## rpnie         0.022592  0.002277 0.020573   0.024 <2e-16 ***
## rtnie         0.049395  0.000512 0.050350   0.051 <2e-16 ***
## te            0.187281  0.005303 0.188700   0.196 <2e-16 ***
## rintref       0.067440  0.002075 0.067636   0.070 <2e-16 ***
## rintmed       0.026803  0.002789 0.026718   0.030 <2e-16 ***
## cde(prop)     0.376155  0.030641 0.356284   0.397 <2e-16 ***
## rintref(prop) 0.360098  0.020701 0.345418   0.373 <2e-16 ***
## rintmed(prop) 0.143118  0.018617 0.136462   0.161 <2e-16 ***
## rpnie(prop)   0.120629  0.008677 0.109013   0.121 <2e-16 ***
## rpm           0.263747  0.009939 0.257133   0.270 <2e-16 ***
## rint          0.503216  0.039318 0.481879   0.535 <2e-16 ***
## rpe           0.623845  0.030641 0.602550   0.644 <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (cde: controlled direct effect; rpnde: randomized analogue of pure natural direct effect; rtnde: randomized analogue of total natural direct effect; rpnie: randomized analogue of pure natural indirect effect; rtnie: randomized analogue of total natural indirect effect; te: total effect; rintref: randomized analogue of reference interaction; rintmed: randomized analogue of mediated interaction; cde(prop): proportion cde; rintref(prop): proportion rintref; rintmed(prop): proportion rintmed; rpnie(prop): proportion rpnie; rpm: randomized analogue of overall proportion mediated; rint: randomized analogue of overall proportion attributable to interaction; rpe: randomized analogue of overall proportion eliminated)
## 
## Relevant variable values: 
## $a
## [1] 1
## 
## $astar
## [1] 0
## 
## $mval
## $mval[[1]]
## [1] 0
\end{verbatim}

Applying an IPTW estimator using the \texttt{CMAverse}, the ATE = 0.1873 and the CDE(M=0) = 0.0704.

\chapter{Estimate the ATE by TMLE}\label{estimate-the-ate-by-tmle}

When estimating a mean counterfactual outcome using g-computation methods, we have to estimate some \(\bar{Q}\) functions (functions of the outcome conditional on the exposures and confounders, \(\bar{Q}=\mathbb{E}\left(Y\mid A,L(0)\right)\)). For example, the Average Total Effect (ATE) is defined as a marginal effect, estimated using the empirical mean of such \(\bar{Q}\) functions:
\begin{equation*}
\hat{\Psi}^{\text{ATE}}_{\text{gcomp}} = \frac{1}{n} \sum_{i=1}^n \left[ \hat{\overline{Q}}(A=1)_i - \hat{\overline{Q}}(A=0)_i \right]
\end{equation*}

Unless the \(\bar{Q}\) functions are not misspecified, its estimate is expected to be biased (and \(\bar{Q}\) are expected to be misspecified, especially if the set of baseline confounders \(L(0)\) is high dimensional, for example if it includes is a large number of variables or continuous variables). In order to improve the estimation of \(\bar{Q}(A,L)\), it is possible to use data-adaptive methods (machine learning algorithms) in order to optimize the bias-variance trade-off. However, this bias-variance trade-off would be optimized for the \(\bar{Q}\) functions, not for the ATE estimate \(\hat{\Psi}^\text{ATE}_\text{gcomp}\). If the \(\bar{Q}\) function is unknown and has to be estimated (preferably by data-adaptive methods), it can be shown that the g-computation estimate of \(\Psi^\text{ATE}\) is asymptotically biased.

The Targeted Maximum Likelihood Estimation (TMLE) method has been developed as an asymptotically linear estimator, so that the estimation of any target parameter in any semiparametric statistical model is unbiased and efficient. In order to estimate a parameter \(\Psi(P_0)\), where \(P_0\) is an unknown probability distribution among a set \(\mathcal{M}\) of possible statistical models, the TMLE is described as a two-step procedure (\citeproc{ref-vanderlaan_book2011}{Laan and Rose 2011}):

\begin{itemize}
\tightlist
\item
  The first step is to obtain an initial estimate of the relevant part (\(\bar{Q}_0\) in our applications) of the probability distribution \(P_0\). Data adaptive methods (machine learning algorithms) can be used to optimize this first step.
\item
  The second step is to update the initial fit in order to ``target toward making an optimal bias-variance tradeoff for the parameter of interest'' \(\Psi(\bar{Q})\).
\end{itemize}

Several R packages have been developed in order to carry out TMLE estimation of causal effects. We will begin using the \texttt{ltmle} package, as it can be used to estimate ATE or CDE. More generally, this package can be used to estimate the counterfactual effects of repeated exposure in time-to-event settings. In the setting of mediation analysis, a controlled direct effect (CDE) corresponds to a sequence of counterfactual interventions on 2 ``exposure variables'': the initial exposure \(A\) and the mediator of interest \(M\). The package can also be used in simpler settings with only one binary or continuous outcome, measure only once at the end a the study.

\section{TMLE for the ATE}\label{tmle-for-the-ate}

In order to illustrate the TMLE procedure, the estimation of a mean counterfactual outcome, denoted \(\Psi(A=1) = \mathbb{E} \left[\bar{Q}(A=1,L(0))\right]\), will be described in detail, following the algorithm implemented in the \texttt{ltmle} package.

The basic steps of the procedure are the following (\citeproc{ref-vanderlaan_book2011}{Laan and Rose 2011}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Estimate \(\bar{Q}_0\). Data-adaptive methods can be used here, the \texttt{ltmle} package relies on the \texttt{SuperLearner} package to fit and predict \(\hat{\bar{Q}}(A=1)\).
\item
  Estimate the treatment mechanism (propensity score) \(g(A=1 \mid L(0))\). Once again, data-adaptive methods can be used to improve the estimation.
\item
  The initial estimator of \(\bar{Q}_0(A=1)\) will be slightly modified using a parametric fluctuation model, in order to reduce the bias when estimating the ATE. For example, the following parametric model of \(\bar{Q}_0(A=1)\) and a ``clever covariate'' \(H = \frac{I(A=1)}{\hat{g}(A=1 \mid L(0))}\) can be applied:
  \begin{equation*}
   \text{logit} P(Y \mid \hat{\bar{Q}}, H) = \hat{\text{logit} \bar{Q}} + \varepsilon H
  \end{equation*}
  This parametric fluctuation model is chosen so that the derivative of its log-likelihood loss function is equal to the appropriate component of the efficient influence curve of the target parameter \(\Psi(A=1)\).
\item
  Modify the initial estimator of \(\bar{Q}_0(A=1)\) with the parametric fluctuation model (using the estimation \(\hat{\varepsilon}\) from the previous step). We denote \(\hat{\bar{Q}}^*(A=1)\) the updated value of \(\hat{\bar{Q}}(A=1)\)
\item
  Use the updated values \(\hat{\bar{Q}}^*(A=1)\) in the substitution estimator to estimate the target parameter \(\Psi(A=1)\) :
  \begin{equation*}
  \hat{\Psi}(A=1)_\text{TMLE} = \frac{1}{n} \sum_{i=1}^n \hat{\bar{Q}}^* (A=1,L(0)) 
  \end{equation*}
\item
  Estimate the efficient influence curve \(D^*(Q_0,g_0)\) :
  \begin{equation*}
  D^*(Q_0,g_0) = \frac{I(A=1)}{g_0(A=1 \mid L(0))}(Y - \bar{Q}_0(A,L(O))) + \bar{Q}_0(A=1,L(0))  - \Psi(A=1)
  \end{equation*}
\end{enumerate}

The variance of the target parameter can then be calculated using the variance of the efficient influence curve:
\begin{equation*}
\text{var} \hat{\Psi}(A=1)_\text{TMLE} = \frac{\text{var} \hat{D}^*}{n}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\DocumentationTok{\#\# 1) Estimate Qbar and predict Qbar when the exposure ("education") is set to 1}
\NormalTok{Q\_fit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu,}
             \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{data\_A1 }\OtherTok{\textless{}{-}}\NormalTok{ df}
\NormalTok{data\_A1}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{1}

\CommentTok{\# predict the Qvar function when setting the exposure to A=1, on the logit scale}
\NormalTok{logitQ }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(Q\_fit, }\AttributeTok{newdata =}\NormalTok{ data\_A1, }\AttributeTok{type =} \StringTok{"link"}\NormalTok{)}

\DocumentationTok{\#\# 2) Estimate the treatment mechanism}
\NormalTok{g\_L }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(edu }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu,}
           \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\CommentTok{\# predict the probabilities g(A=1 | L(0)) = P(A0\_PM2.5=1|L(0))}
\NormalTok{g1\_L }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_L, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\FunctionTok{head}\NormalTok{(g1\_L)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         1         2         3         4         5         6 
## 0.6608369 0.6071248 0.6071248 0.4495011 0.6071248 0.6071248
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# It is useful to check the distribution of gA\_L, as values close to 0 or 1 are }
\CommentTok{\# indicators of near positivity violation and can result in large variance for the }
\CommentTok{\# estimation. }
\CommentTok{\# In case of near positivity violation, gA\_L values can be truncated to decrease}
\CommentTok{\# the variance (at the cost a increased bias).}
\FunctionTok{summary}\NormalTok{(g1\_L)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.4495  0.5073  0.6071  0.5953  0.6608  0.6608
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# there is no positivity issues in this example.}

\DocumentationTok{\#\# 3) Determine a parametric family of fluctuations of Qbar. }
\CommentTok{\# The fluctuation model is a model of logitQbar and g(A=1|L(0)) }

\CommentTok{\# The clever covariate H(A,L(0)) depends on g(A=1|L(0)):}
\NormalTok{H }\OtherTok{\textless{}{-}}\NormalTok{ (df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ g1\_L}

\CommentTok{\# Update the initial fit Qbar from step 1.}
\CommentTok{\# This is achieved by holding Qbar fixed (as intercept) while estimating the}
\CommentTok{\# coefficient epsilon for H}

\CommentTok{\# for example we could use the following fluctuation model (from the "Targeted }
\CommentTok{\# Learning" book)}
\NormalTok{update\_fit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{death }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{offset}\NormalTok{(logitQ) }\SpecialCharTok{+}\NormalTok{ H,}
                  \AttributeTok{family =} \StringTok{"quasibinomial"}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(update\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             H 
## -1.658129e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qstar }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(update\_fit, }\AttributeTok{data =} \FunctionTok{data.frame}\NormalTok{(logitQ, H), }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\CommentTok{\# In the ltmle package, the fluctuation parametric model is slightly different}
\CommentTok{\# (but with the same purpose). The "clever covariate" H is scaled and used as a }
\CommentTok{\# weight in the parametric quasi{-}logistic regression}
\NormalTok{S1 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{update\_fit\_ltmle }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{death }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ S1 }\SpecialCharTok{+} \FunctionTok{offset}\NormalTok{(logitQ),}
                        \AttributeTok{family =} \StringTok{"quasibinomial"}\NormalTok{,}
                        \AttributeTok{weights =} \FunctionTok{scale}\NormalTok{(H, }\AttributeTok{center =} \ConstantTok{FALSE}\NormalTok{))}
\FunctionTok{coef}\NormalTok{(update\_fit\_ltmle)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           S1 
## -2.80861e-05
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 4) Update the initial estimate of Qbar using the fluctuation parametric model}
\NormalTok{Qstar\_ltmle }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(update\_fit\_ltmle, }
                       \AttributeTok{data =} \FunctionTok{data.frame}\NormalTok{(logitQ, H), }
                       \AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(Qstar\_ltmle)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         1         2         3         4         5         6 
## 0.3073922 0.4243074 0.4243074 0.3015693 0.4243074 0.4243074
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#         1         2         3         4         5         6 }
\CommentTok{\# 0.2872412 0.3441344 0.3441344 0.2591356 0.3441344 0.3441344}

\DocumentationTok{\#\# 5) Obtain the substition estimator of Psi\_Ais1}
\NormalTok{Psi\_Ais1 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Qstar\_ltmle)}
\NormalTok{Psi\_Ais1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3306626
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 5) Calculate standard errors based on the influence curve of the TMLE}
\NormalTok{IC }\OtherTok{\textless{}{-}}\NormalTok{ H }\SpecialCharTok{*}\NormalTok{ (df}\SpecialCharTok{$}\NormalTok{death }\SpecialCharTok{{-}}\NormalTok{ Qstar\_ltmle) }\SpecialCharTok{+}\NormalTok{ Qstar\_ltmle }\SpecialCharTok{{-}}\NormalTok{ Psi\_Ais1}
\FunctionTok{head}\NormalTok{(IC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           1           2           3           4           5           6 
## -0.48842639  0.09364473  0.09364473  1.52469745  0.09364473  1.04187255
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the influence curve has a mean of 0}
\FunctionTok{summary}\NormalTok{(IC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -0.69999 -0.48843 -0.02909  0.00000  0.09364  1.52470
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The standard error of the target parameter Psi(A=1) can be estimated by :}
\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(IC)}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(df))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.006090826
\end{verbatim}

We can see that we can get the same output using the \texttt{ltmle} package (cf.~\texttt{?ltmle} to see how the function works):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\FunctionTok{library}\NormalTok{(ltmle)}

\CommentTok{\# The Qform and gform arguments are defined from the DAG}
\NormalTok{Qform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{death=}\StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{)}
\NormalTok{gform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"edu \textasciitilde{} sex + low\_par\_edu"}\NormalTok{)}

\CommentTok{\# in the ltmle package, the data set should be formated so that the order of the }
\CommentTok{\# columns corresponds to the time{-}ordering of the model}
\NormalTok{data\_ltmle }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }
                     \AttributeTok{select =} \FunctionTok{c}\NormalTok{(sex, low\_par\_edu, edu, death))}

\CommentTok{\# the counterfactual intervention is defined in the abar argument}
\NormalTok{abar }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{Psi\_Ais1 }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(data\_ltmle,}
                  \AttributeTok{Anodes =} \StringTok{"edu"}\NormalTok{,}
                  \AttributeTok{Ynodes =} \StringTok{"death"}\NormalTok{,}
                  \AttributeTok{Qform =}\NormalTok{ Qform,}
                  \AttributeTok{gform =}\NormalTok{ gform,}
                  \AttributeTok{gbounds =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{), }\CommentTok{\# by default, g function truncated at 0.01}
                  \AttributeTok{abar =}\NormalTok{ abar,}
                  \AttributeTok{SL.library =} \StringTok{"glm"}\NormalTok{,}
                  \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{)}

\CommentTok{\# from the ltmle() function, we can get the point estimate, its standard error, }
\CommentTok{\# 95\% confidence interval and the p{-}value for the null hypothesis.}
\FunctionTok{summary}\NormalTok{(Psi\_Ais1, }\StringTok{"tmle"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  tmle 
## Call:
## ltmle(data = data_ltmle, Anodes = "edu", Ynodes = "death", Qform = Qform, 
##     gform = gform, abar = abar, gbounds = c(0.01, 1), SL.library = "glm", 
##     variance.method = "ic")
## 
##    Parameter Estimate:  0.33066 
##     Estimated Std Err:  0.0060908 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.31872, 0.3426)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The ltmle() function returns an object with several outputs.}
\CommentTok{\# We can see that g functions are the same as in the previous manual calculation}
\FunctionTok{head}\NormalTok{(Psi\_Ais1}\SpecialCharTok{$}\NormalTok{cum.g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]
## [1,] 0.6608369
## [2,] 0.6071248
## [3,] 0.6071248
## [4,] 0.4495011
## [5,] 0.6071248
## [6,] 0.6071248
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# we can get the estimation of the epsilon parameter from the fluctuation model}
\NormalTok{Psi\_Ais1}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{Qstar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $death
## 
## Call:  glm(formula = formula, family = family, data = data.frame(data, 
##     weights), weights = weights, control = glm.control(maxit = 100))
## 
## Coefficients:
##         S1  
## -2.809e-05  
## 
## Degrees of Freedom: 5953 Total (i.e. Null);  5952 Residual
## Null Deviance:       7342 
## Residual Deviance: 7342  AIC: NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# we can get the updated Qbar functions:}
\FunctionTok{head}\NormalTok{(Psi\_Ais1}\SpecialCharTok{$}\NormalTok{Qstar)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.3073922 0.4243074 0.4243074 0.3015693 0.4243074 0.4243074
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# we can get the influence curve }
\FunctionTok{head}\NormalTok{(Psi\_Ais1}\SpecialCharTok{$}\NormalTok{IC}\SpecialCharTok{$}\NormalTok{tmle)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.48842639  0.09364473  0.09364473  1.52469745  0.09364473  1.04187255
\end{verbatim}

In practice, it is recommended to apply data-adaptive algorithms to estimate \(\bar{Q}\) and \(g\) functions: the \texttt{ltmle} package relies on the \texttt{SuperLearner} package. As indicated in the \href{https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html}{Guide to SuperLearner},
The \texttt{SuperLearner} is ``an algorithm that uses cross-validation to estimate the performance of multiple machine learning models, or the same model with different settings. It then creates an optimal weighted average of those models (ensemble learning) using the test data performance.''

Here is an example for our estimation of the Average Total Effect (ATE).

The \texttt{SuperLearner} package includes a set of algorithms with default parameters (showed by \texttt{listWrappers()}). Because the simulated data set only have 2 binary baseline variables, the set \(\mathcal{M}\) of possible statistical models is limited. In order to estimate the ATE, we will include a library with:

\begin{itemize}
\tightlist
\item
  \texttt{SL.mean}, the null-model which only predict the marginal mean (it can be used as a reference for a bad model);
\item
  \texttt{SL.glm}, a glm using the main terms from the \texttt{Qform} and \texttt{gform} argument; We will also add a \texttt{screen} algorithm which first applies a selection prodedure on the predictors of the learner.
\item
  \texttt{SL.interaction.back}, a step-by-step backward GLM prodecure (based on the AIC), starting with all \(2 \times 2\) interactions between main terms. This function is customized from the \texttt{SL.step.interaction} available with the \texttt{ltmle} and \texttt{SuperLearner} packages, where the \texttt{direction} argument is set to \texttt{both} by default.
\item
  \texttt{SL.hal9001} fit the ``Highly Adaptive Lasso (HAL) algorithm. See the \href{https://cran.r-project.org/web//packages/hal9001/vignettes/intro_hal9001.html}{vignette} for more information on the HAL algorithm. One of its advantage is a very fast rate of convergence.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(SuperLearner)}
\FunctionTok{library}\NormalTok{(hal9001)}
\CommentTok{\# Below, we use the same ltmle() function than previously, }
\CommentTok{\# and specify a family of algorithms to be used with the SuperLearner}

\DocumentationTok{\#\# we can change the default argument of the SL.xgboost algorithm and the }
\DocumentationTok{\#\# SL.step.interaction algorithm}

\CommentTok{\# We can check how arguments are used in the pre{-}specified algorithms}
\NormalTok{SL.step.interaction}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## function (Y, X, newX, family, direction = "both", trace = 0, 
##     k = 2, ...) 
## {
##     fit.glm <- glm(Y ~ ., data = X, family = family)
##     fit.step <- step(fit.glm, scope = Y ~ .^2, direction = direction, 
##         trace = trace, k = k)
##     pred <- predict(fit.step, newdata = newX, type = "response")
##     fit <- list(object = fit.step)
##     out <- list(pred = pred, fit = fit)
##     class(out$fit) <- c("SL.step")
##     return(out)
## }
## <bytecode: 0x00000251e9b34bd8>
## <environment: namespace:SuperLearner>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# function (Y, X, newX, family, direction = "both", trace = 0, }
\CommentTok{\#     k = 2, ...) }
\CommentTok{\# \{}
\CommentTok{\#     fit.glm \textless{}{-} glm(Y \textasciitilde{} ., data = X, family = family)}
\CommentTok{\#     fit.step \textless{}{-} step(fit.glm, scope = Y \textasciitilde{} .\^{}2, direction = direction, }
\CommentTok{\#         trace = trace, k = k)}
\CommentTok{\#     pred \textless{}{-} predict(fit.step, newdata = newX, type = "response")}
\CommentTok{\#     fit \textless{}{-} list(object = fit.step)}
\CommentTok{\#     out \textless{}{-} list(pred = pred, fit = fit)}
\CommentTok{\#     class(out$fit) \textless{}{-} c("SL.step")}
\CommentTok{\#     return(out)}
\CommentTok{\# \}}
\CommentTok{\# \textless{}bytecode: 0x000001b965ed0dc0\textgreater{}}
\CommentTok{\# \textless{}environment: namespace:SuperLearner\textgreater{}}

\CommentTok{\# the SL.step.interaction can be adapted, changing some arguments:}
\NormalTok{SL.interaction.back }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(...) \{}
  \FunctionTok{SL.step.interaction}\NormalTok{(..., }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\NormalTok{\}}

\DocumentationTok{\#\# The HAL algorithm implemented by default does not deal correctly with }
\DocumentationTok{\#\# continuous outcome, }
\DocumentationTok{\#\# However, we can define your own learner algorithm, following the template:}
\NormalTok{SL.template}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## function (Y, X, newX, family, obsWeights, id, ...) 
## {
##     if (family$family == "gaussian") {
##     }
##     if (family$family == "binomial") {
##     }
##     pred <- numeric()
##     fit <- vector("list", length = 0)
##     class(fit) <- c("SL.template")
##     out <- list(pred = pred, fit = fit)
##     return(out)
## }
## <bytecode: 0x00000251e9855858>
## <environment: namespace:SuperLearner>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# function (Y, X, newX, family, obsWeights, id, ...) }
\CommentTok{\# \{}
\CommentTok{\#     if (family$family == "gaussian") \{}
\CommentTok{\#     \}}
\CommentTok{\#     if (family$family == "binomial") \{}
\CommentTok{\#     \}}
\CommentTok{\#     pred \textless{}{-} numeric()}
\CommentTok{\#     fit \textless{}{-} vector("list", length = 0)}
\CommentTok{\#     class(fit) \textless{}{-} c("SL.template")}
\CommentTok{\#     out \textless{}{-} list(pred = pred, fit = fit)}
\CommentTok{\#     return(out)}
\CommentTok{\# \}}
\CommentTok{\# \textless{}bytecode: 0x00000291b737f2e0\textgreater{}}
\CommentTok{\# \textless{}environment: namespace:SuperLearner\textgreater{}}

\DocumentationTok{\#\# We define your own HAL algorithm that can run on both continuous and binary outcomes}
\NormalTok{SL.hal9001.Qbar }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{ (Y, X, newX, family, obsWeights, id, }\AttributeTok{max\_degree =} \DecValTok{2}\NormalTok{, }
                             \AttributeTok{smoothness\_orders =} \DecValTok{1}\NormalTok{, }\AttributeTok{num\_knots =} \DecValTok{5}\NormalTok{, ...) \{}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.matrix}\NormalTok{(X)) }
\NormalTok{    X }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(X)}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(newX) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.matrix}\NormalTok{(newX)) }
\NormalTok{    newX }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(newX)}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(Y)) }\SpecialCharTok{==} \DecValTok{2}\NormalTok{) \{ }\CommentTok{\# for binomial family}
\NormalTok{    hal\_fit }\OtherTok{\textless{}{-}}\NormalTok{ hal9001}\SpecialCharTok{::}\FunctionTok{fit\_hal}\NormalTok{(}\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }
                                \AttributeTok{weights =}\NormalTok{ obsWeights, }\AttributeTok{id =}\NormalTok{ id, }\AttributeTok{max\_degree =}\NormalTok{ max\_degree, }
                                \AttributeTok{smoothness\_orders =}\NormalTok{ smoothness\_orders, }\AttributeTok{num\_knots =}\NormalTok{ num\_knots, }
\NormalTok{                                ...)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(Y)) }\SpecialCharTok{\textgreater{}} \DecValTok{2}\NormalTok{) \{ }\CommentTok{\# for quasibinomial family}
\NormalTok{    hal\_fit }\OtherTok{\textless{}{-}}\NormalTok{ hal9001}\SpecialCharTok{::}\FunctionTok{fit\_hal}\NormalTok{(}\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }
                                \AttributeTok{weights =}\NormalTok{ obsWeights, }\AttributeTok{id =}\NormalTok{ id, }\AttributeTok{max\_degree =}\NormalTok{ max\_degree, }
                                \AttributeTok{smoothness\_orders =}\NormalTok{ smoothness\_orders, }\AttributeTok{num\_knots =}\NormalTok{ num\_knots, }
\NormalTok{                                ...)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(newX)) \{}
\NormalTok{    pred }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{::}\FunctionTok{predict}\NormalTok{(hal\_fit, }\AttributeTok{new\_data =}\NormalTok{ newX)}
\NormalTok{  \}}
  \ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    pred }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{::}\FunctionTok{predict}\NormalTok{(hal\_fit, }\AttributeTok{new\_data =}\NormalTok{ X)}
\NormalTok{  \}}
\NormalTok{  fit }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{object =}\NormalTok{ hal\_fit)}
  \FunctionTok{class}\NormalTok{(fit) }\OtherTok{\textless{}{-}} \StringTok{"SL.hal9001"}
\NormalTok{  out }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{pred =}\NormalTok{ pred, }\AttributeTok{fit =}\NormalTok{ fit)}
  \FunctionTok{return}\NormalTok{(out)}
\NormalTok{\}}
\FunctionTok{environment}\NormalTok{(SL.hal9001.Qbar) }\OtherTok{\textless{}{-}}\FunctionTok{asNamespace}\NormalTok{(}\StringTok{"SuperLearner"}\NormalTok{)}

\DocumentationTok{\#\# the algorithms we would like to use can be specified separately for the Q and }
\CommentTok{\# g functions}
\NormalTok{SL.library }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{Q=}\FunctionTok{list}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{, }\StringTok{"SL.glm"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"SL.glm"}\NormalTok{, }\StringTok{"screen.corP"}\NormalTok{), }
                       \StringTok{"SL.interaction.back"}\NormalTok{, }\StringTok{"SL.hal9001"}\NormalTok{),}
                   \AttributeTok{g=}\FunctionTok{list}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{, }\StringTok{"SL.glm"}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"SL.glm"}\NormalTok{, }\StringTok{"screen.corP"}\NormalTok{), }
                       \StringTok{"SL.interaction.back"}\NormalTok{, }\StringTok{"SL.hal9001"}\NormalTok{))}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{Psi\_ATE\_tmle }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data\_ltmle,}
                      \AttributeTok{Anodes =} \StringTok{"edu"}\NormalTok{,}
                      \AttributeTok{Ynodes =} \StringTok{"death"}\NormalTok{,}
                      \AttributeTok{Qform =}\NormalTok{ Qform,}
                      \AttributeTok{gform =}\NormalTok{ gform,}
                      \AttributeTok{gbounds =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                      \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{\# vector of the counterfactual treatment}
                      \AttributeTok{SL.library =}\NormalTok{ SL.library,}
                      \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{)}
\CommentTok{\# The estimation is more computer intensive}
\CommentTok{\# The function give the ATE on the difference scale (as well, as RR and OR)}
\FunctionTok{summary}\NormalTok{(Psi\_ATE\_tmle, }\AttributeTok{estimator =} \StringTok{"tmle"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  tmle 
## Call:
## ltmle(data = data_ltmle, Anodes = "edu", Ynodes = "death", Qform = Qform, 
##     gform = gform, abar = list(1, 0), gbounds = c(0.01, 1), SL.library = SL.library, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  0.33064 
##     Estimated Std Err:  0.0060897 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.3187, 0.34258) 
## 
## Control Estimate:
##    Parameter Estimate:  0.14418 
##     Estimated Std Err:  0.0056066 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.13319, 0.15517) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.18646 
##     Estimated Std Err:  0.0082369 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.17031, 0.2026) 
## 
## Relative Risk:
##    Parameter Estimate:  2.2932 
##   Est Std Err log(RR):  0.042862 
##               p-value:  <2e-16 
##     95% Conf Interval: (2.1084, 2.4942) 
## 
## Odds Ratio:
##    Parameter Estimate:  2.932 
##   Est Std Err log(OR):  0.052886 
##               p-value:  <2e-16 
##     95% Conf Interval: (2.6433, 3.2522)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Additive Treatment Effect:}
\CommentTok{\#    Parameter Estimate:  0.18646 }
\CommentTok{\#     Estimated Std Err:  0.0082369 }
\CommentTok{\#               p{-}value:  \textless{}2e{-}16 }
\CommentTok{\#     95\% Conf Interval: (0.17031, 0.2026) }
    
\DocumentationTok{\#\# We can see how the SuperLearner used the algorithms for the g function}
\CommentTok{\# we see that the Risk is high for the bad model (SL.mean)}
\CommentTok{\# and very similar for the other models}
\NormalTok{Psi\_ATE\_tmle}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{g[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $edu
##                              Risk        Coef
## SL.mean_All             0.2409651 0.004074661
## SL.glm_All              0.2358587 0.000000000
## SL.glm_screen.corP      0.2358587 0.995925339
## SL.interaction.back_All 0.2358587 0.000000000
## SL.hal9001_All          0.2358824 0.000000000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# We can see how the SuperLearner used the algorithms for the Q function}
\NormalTok{Psi\_ATE\_tmle}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [[1]]$death
##                              Risk      Coef
## SL.mean_All             0.1905554 0.0000000
## SL.glm_All              0.1775983 0.6619501
## SL.glm_screen.corP      0.1775983 0.0000000
## SL.interaction.back_All 0.1775983 0.0000000
## SL.hal9001_All          0.1776157 0.3380499
## 
## 
## [[2]]
## [[2]]$death
##                              Risk      Coef
## SL.mean_All             0.1905554 0.0000000
## SL.glm_All              0.1775983 0.6619501
## SL.glm_screen.corP      0.1775983 0.0000000
## SL.interaction.back_All 0.1775983 0.0000000
## SL.hal9001_All          0.1776157 0.3380499
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The SuperLearner predicts the Q function using a mix between the glm and }
\CommentTok{\# the HAL algorithm. }
\CommentTok{\# However, the choice between the 2 SL.glm and SL.interaction.back }
\CommentTok{\# was arbitrary: as we can see the Risk is exactly the same for the 3 }
\CommentTok{\# algorithms. The final model from the step{-}by{-}step procedure and the glm after}
\CommentTok{\# the screening procedure were probably the same "main term" glm.}


\DocumentationTok{\#\# The \textasciigrave{}ltmle\textasciigrave{} package can also be used to estimate the effect of categorical }
\DocumentationTok{\#\# exposures on continous outcomes}
\NormalTok{Qform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{score=}\StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{)}
\NormalTok{gform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"edu \textasciitilde{} sex + low\_par\_edu"}\NormalTok{)}

\NormalTok{SL.library }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{Q=}\FunctionTok{c}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{,}\StringTok{"SL.glm"}\NormalTok{,}\StringTok{"SL.interaction.back"}\NormalTok{, }\StringTok{"SL.hal9001.Qbar"}\NormalTok{),}
                   \AttributeTok{g=}\FunctionTok{c}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{,}\StringTok{"SL.glm"}\NormalTok{,}\StringTok{"SL.interaction.back"}\NormalTok{, }\StringTok{"SL.hal9001"}\NormalTok{))}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{Psi\_ATE\_tmle\_score }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(df, }
                                          \AttributeTok{select =} \FunctionTok{c}\NormalTok{(sex, low\_par\_edu,}
\NormalTok{                                                     edu,}
\NormalTok{                                                     score)),}
                      \AttributeTok{Anodes =} \StringTok{"edu"}\NormalTok{,}
                      \AttributeTok{Ynodes =} \StringTok{"score"}\NormalTok{,}
                      \AttributeTok{Qform =}\NormalTok{ Qform,}
                      \AttributeTok{gform =}\NormalTok{ gform,}
                      \AttributeTok{gbounds =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                      \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{\# vector of the counterfactual treatment }
                      \AttributeTok{SL.library =}\NormalTok{ SL.library,}
                      \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(Psi\_ATE\_tmle\_score, }\AttributeTok{estimator =} \StringTok{"tmle"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  tmle 
## Call:
## ltmle(data = subset(df, select = c(sex, low_par_edu, edu, score)), 
##     Anodes = "edu", Ynodes = "score", Qform = Qform, gform = gform, 
##     abar = list(1, 0), gbounds = c(0.01, 1), SL.library = SL.library, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  22.496 
##     Estimated Std Err:  0.25199 
##               p-value:  <2e-16 
##     95% Conf Interval: (22.002, 22.989) 
## 
## Control Estimate:
##    Parameter Estimate:  42.256 
##     Estimated Std Err:  0.28487 
##               p-value:  <2e-16 
##     95% Conf Interval: (41.698, 42.814) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  -19.76 
##     Estimated Std Err:  0.37746 
##               p-value:  <2e-16 
##     95% Conf Interval: (-20.5, -19.021)
\end{verbatim}

On the difference scale, the TMLE estimation of the ATE from the \texttt{ltmle} package for death probability and quantitative score is +18.65\% (95\% CI={[}17.03\%, +20.26\%{]}) and -19.76 {[}-20.5, -19.021{]} respectively.

Note that the \texttt{ltmle} package can also be used to calculate the IPTW estimation of the ATE and the CDE.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# using the output from the previous ltmle() procedure}
\FunctionTok{summary}\NormalTok{(Psi\_ATE\_tmle, }\AttributeTok{estimator =} \StringTok{"iptw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  iptw 
## Call:
## ltmle(data = data_ltmle, Anodes = "edu", Ynodes = "death", Qform = Qform, 
##     gform = gform, abar = list(1, 0), gbounds = c(0.01, 1), SL.library = SL.library, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  0.33069 
##     Estimated Std Err:  0.0061262 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.31868, 0.3427) 
## 
## Control Estimate:
##    Parameter Estimate:  0.14409 
##     Estimated Std Err:  0.0056297 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.13306, 0.15513) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.18659 
##     Estimated Std Err:  0.0083201 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.17029, 0.2029) 
## 
## Relative Risk:
##    Parameter Estimate:  2.295 
##   Est Std Err log(RR):  0.04324 
##               p-value:  <2e-16 
##     95% Conf Interval: (2.1085, 2.4979) 
## 
## Odds Ratio:
##    Parameter Estimate:  2.9348 
##   Est Std Err log(OR):  0.053383 
##               p-value:  <2e-16 
##     95% Conf Interval: (2.6432, 3.2585)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Additive Treatment Effect:}
\CommentTok{\#    Parameter Estimate:  0.18659 }
\CommentTok{\#     Estimated Std Err:  0.0083201 }
\CommentTok{\#               p{-}value:  \textless{}2e{-}16 }
\CommentTok{\#     95\% Conf Interval: (0.17029, 0.2029) }

\FunctionTok{summary}\NormalTok{(Psi\_ATE\_tmle\_score, }\AttributeTok{estimator =} \StringTok{"iptw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  iptw 
## Call:
## ltmle(data = subset(df, select = c(sex, low_par_edu, edu, score)), 
##     Anodes = "edu", Ynodes = "score", Qform = Qform, gform = gform, 
##     abar = list(1, 0), gbounds = c(0.01, 1), SL.library = SL.library, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  22.491 
##     Estimated Std Err:  0.25389 
##               p-value:  <2e-16 
##     95% Conf Interval: (21.993, 22.989) 
## 
## Control Estimate:
##    Parameter Estimate:  42.254 
##     Estimated Std Err:  0.2873 
##               p-value:  <2e-16 
##     95% Conf Interval: (41.691, 42.817) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  -19.763 
##     Estimated Std Err:  0.38341 
##               p-value:  <2e-16 
##     95% Conf Interval: (-20.515, -19.012)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Additive Treatment Effect:}
\CommentTok{\#    Parameter Estimate:  {-}19.763 }
\CommentTok{\#     Estimated Std Err:  0.38341 }
\CommentTok{\#               p{-}value:  \textless{}2e{-}16 }
\CommentTok{\#     95\% Conf Interval: ({-}20.515, {-}19.012) }
\end{Highlighting}
\end{Shaded}

On a difference scale, the IPTW estimation of the ATE from the \texttt{ltmle} package for death probability and the quantitative score is +18.66\% (95\% CI={[}+17.03\%, +20.29\%{]}) and -19.76 {[}-20.52, -19.01{]}, respectively.

\chapter{\texorpdfstring{Estimate the CDE using the \texttt{ltmle} package}{Estimate the CDE using the ltmle package}}\label{estimate-the-cde-using-the-ltmle-package}

The ltmle package can be used to estimate controlled direct effects by:

\begin{itemize}
\tightlist
\item
  g-computation by iterative conditional expectation (ICE),
\item
  IPTW,
\item
  or TMLE.
\end{itemize}

\section{G-computation by iterative conditional expectation}\label{ChapGcomp-CDE-ICE}

\subsection{Algorithm and manual calculation}\label{algorithm-and-manual-calculation}

The following steps describe the implementation of the g-computation estimator by iterative conditional expectation (ICE) for the component \(\mathbb{E}(Y_{A=a^\prime,M=m})\) used in the definition of CDE \(\Psi^{\text{CDE}_m} = \mathbb{E}(Y_{A=1,M=m}) - \mathbb{E}(Y_{A=0,M=m})\). Interestingly, there is no need to estimate or simulate \(L(1)\) density with this method.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Fit a logistic or a linear regression of the final outcome, conditional on the exposure \(A\), the mediator \(M\) and all the parents of \(Y\) preceding \(M\), to estimate \(\overline{Q}_{L(2)} = \mathbb{E}(Y \mid L(0),A,L(1),M)\);
\item
  Use this estimate to predict an outcome for each subject \(\hat{\overline{Q}}_{L(2)}(A=a^\prime,M=m)_i\), by evaluating the regression fit \(\overline{Q}_{L(2)}\) at the chosen value for the exposure \(A=a^\prime\) and the mediator \(M=m\);
\item
  Fit a quasibinomial or a linear regression of the predicted values \(\hat{\overline{Q}}_{L(2)}(A=a^\prime,M=m)_i\) conditional on the exposure \(A\) and baseline confounders \(L(0)\) to estimate \(\overline{Q}_{L(1)} = \mathbb{E}\left(\hat{\overline{Q}}_{L(2)}(A=a^\prime,M=m) \middle| L(0),A\right)\);
\item
  Use this estimate to predict the outcome \(\hat{\overline{Q}}_{L(1)}(A=a^\prime)_i\) for each subject, by evaluating the regression fit \(\overline{Q}_{L(1)}\) at \(A=a^\prime\);
\item
  Use the sample mean to estimate \(\Psi^{\text{CDE}_m}_{\text{gcomp}}\)
  \begin{equation}
  \hat{\Psi}^{\text{CDE}_m}_{\text{gcomp}} = \frac{1}{n} \sum_{i=1}^n \left[ \hat{\overline{Q}}_{L(1)}(A=1)_i - \hat{\overline{Q}}_{L(1)}(A=0)_i \right]
  \end{equation}
\end{enumerate}

Note that G-computation by iterative expectation is preferable if the set of intermediate confounders \(L(1)\) is high-dimensional as we only need to fit 2 models by counterfactual scenario (for a whole set of \(L(1)\) variables) in the procedure described below, whereas at least 1 model by \(L(1)\) variable and the model of the outcome are needed with parametric g-computation.

In the following example, we will focus on the estimand \(CDE(M=0) = \mathbb{E}(Y_{A=1,M=0}) - \mathbb{E}(Y_{A=0,M=0})\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\DocumentationTok{\#\# 1) Regress the outcome on L0, A, L1 and M (and the A*M interaction if appropriate)}
\NormalTok{death\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ phys }\SpecialCharTok{+}\NormalTok{ occupation }\SpecialCharTok{+}
\NormalTok{                     smoking }\SpecialCharTok{+}\NormalTok{ edu}\SpecialCharTok{:}\NormalTok{smoking,}
                   \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
                       
\NormalTok{score\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ phys }\SpecialCharTok{+}\NormalTok{ occupation }\SpecialCharTok{+}
\NormalTok{                     smoking }\SpecialCharTok{+}\NormalTok{ edu}\SpecialCharTok{:}\NormalTok{smoking,}
                   \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\DocumentationTok{\#\# 2) Generate predicted values by evaluating the regression setting the exposure}
\DocumentationTok{\#\#    and the mediator at exposure history of interest:}
\DocumentationTok{\#\#    \{A=1,M=0\},\{A=0,M=0\}}
\NormalTok{data\_Ais0\_Mis0 }\OtherTok{\textless{}{-}}\NormalTok{ data\_Ais1\_Mis0 }\OtherTok{\textless{}{-}}\NormalTok{ df}

\NormalTok{data\_Ais0\_Mis0}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{data\_Ais0\_Mis0}\SpecialCharTok{$}\NormalTok{smoking }\OtherTok{\textless{}{-}} \DecValTok{0}

\NormalTok{data\_Ais1\_Mis0}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{data\_Ais1\_Mis0}\SpecialCharTok{$}\NormalTok{smoking }\OtherTok{\textless{}{-}} \DecValTok{0}

\NormalTok{Q\_L2\_death\_A0M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(death\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais0\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{Q\_L2\_death\_A1M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(death\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais1\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\NormalTok{Q\_L2\_score\_A0M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(score\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais0\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{Q\_L2\_score\_A1M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(score\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais1\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\DocumentationTok{\#\# 3) Regress the predicted values conditional on the exposure A}
\DocumentationTok{\#\#    and baseline confounders L(0)}
\NormalTok{L1\_death\_A0M0\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(Q\_L2\_death\_A0M0 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu,}
                           \AttributeTok{family =} \StringTok{"quasibinomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{L1\_death\_A1M0\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(Q\_L2\_death\_A1M0 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu,}
                           \AttributeTok{family =} \StringTok{"quasibinomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\NormalTok{L1\_score\_A0M0\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(Q\_L2\_score\_A0M0 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu,}
                           \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{L1\_score\_A1M0\_model }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(Q\_L2\_score\_A1M0 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu,}
                           \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}

\DocumentationTok{\#\# 4) generate predicted values by evaluating the regression at exposure }
\DocumentationTok{\#\#    of interest: \{A=1\} \& \{A=0\}}
\NormalTok{Q\_L1\_death\_A0M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(L1\_death\_A0M0\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais0\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{Q\_L1\_death\_A1M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(L1\_death\_A1M0\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais1\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\NormalTok{Q\_L1\_score\_A0M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(L1\_score\_A0M0\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais0\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{Q\_L1\_score\_A1M0 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(L1\_score\_A1M0\_model, }
                           \AttributeTok{newdata =}\NormalTok{ data\_Ais1\_Mis0, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\DocumentationTok{\#\# 5) Take empirical mean of final predicted outcomes to estimate CDE}
\CommentTok{\# CDE setting M=0}
\NormalTok{CDE\_death\_m0\_gcomp\_ice }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Q\_L1\_death\_A1M0) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Q\_L1\_death\_A0M0)}
\NormalTok{CDE\_death\_m0\_gcomp\_ice}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.07202748
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{CDE\_score\_m0\_gcomp\_ice }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Q\_L1\_score\_A1M0) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(Q\_L1\_score\_A0M0)}
\NormalTok{CDE\_score\_m0\_gcomp\_ice}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -12.04431
\end{verbatim}

Applying g-computation by iterative expectation, the CDE setting the mediator to 0 is +7.20\% for death and -12.04 for the quantitative score.

95\% confidence intervals can be estimated by bootstrap methods.

\subsection{\texorpdfstring{G-computation by ICE using the \texttt{ltmle} package}{G-computation by ICE using the ltmle package}}\label{g-computation-by-ice-using-the-ltmle-package}

The \texttt{ltmle} package can be used to estimate Controlled Direct Effects by g-computation, as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ltmle)}
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\CommentTok{\# the data set should be composed of continuous or binary variables,}
\CommentTok{\# ordered following the cause{-}effect sequence of each variables.}
\CommentTok{\# Note that within a set of exposures or intermediate confounders measured at a}
\CommentTok{\# single discrete time t, any causal sequence can be applied (for example,}
\CommentTok{\# with several L1 variable, it can be \{L1.1, L1.2, L1.3\} or \{L1.2,L1.3,L1.1\},}
\CommentTok{\# without any consequences on the estimation.}
\NormalTok{df\_death }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(X, subjid, score))}
\NormalTok{df\_score }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(X, subjid, death))}

\DocumentationTok{\#\# 1) Define Q formulas (Qbar\_L1 and Qbar\_Y functions)}
\NormalTok{Q\_formulas\_death }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{phys =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{,}
                      \AttributeTok{death =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + phys + occupation +}
\StringTok{                               edu * smoking"}\NormalTok{) }\CommentTok{\# add interaction}
\NormalTok{Q\_formulas\_score }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{phys =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{,}
                    \AttributeTok{score =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + phys + occupation +}
\StringTok{                             edu * smoking"}\NormalTok{) }\CommentTok{\# add interaction}
\DocumentationTok{\#\# 2) Define g formulas (needed for the ltmle package) but they are not used}
\DocumentationTok{\#\#    with the g{-}computation estimator}
\NormalTok{g\_formulas }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"edu \textasciitilde{} sex + low\_par\_edu"}\NormalTok{, }
                \StringTok{"smoking \textasciitilde{} sex + low\_par\_edu + edu + phys + occupation"}\NormalTok{)}

\DocumentationTok{\#\# 3) Use the ltmle() function}
\CommentTok{\# arguments:}
\CommentTok{\#  {-} Anodes: indicate the exposure and the mediator variables}
\CommentTok{\#  {-} Lnodes: indicate the intermediate confounders (+/{-} baseline confounders)}
\CommentTok{\#  {-} Cnodes: censoring nodes, useless in our example}
\CommentTok{\#  {-} Ynodes: outcome variable}
\CommentTok{\#  {-} survivalOutcome = FALSE in our example}
\CommentTok{\#  {-} abar: list of the two values used to define counterfactual outcomes}
\CommentTok{\#          for the contrast of interest. For example, setting M=0,}
\CommentTok{\#          CDE(M=0) = E(Y\_\{A=1,M=0\}) {-} E(Y\_\{A=0,M=0\})}
\CommentTok{\#  {-} rule: to define dynamic rules (useless in our example)}
\CommentTok{\#  {-} gbounds = c(0.01, 1) by default. This parameter is not used with g{-}computation}
\CommentTok{\#  {-} Yrange = NULL, can be used to define range (min,max) for continuous outcomes}
\CommentTok{\#  {-} SL.library = "glm",  will apply main terms glm models.}
\CommentTok{\#                 The argument can be used to specify SuperLearner libraries.}
\CommentTok{\#                 However, simple glm models might be preferable as data.adaptive}
\CommentTok{\#                 algorithms rely on cross{-}validation, which is difficult and long to}
\CommentTok{\#                 implement with the bootstrap procedure needed for 95\% confidence}
\CommentTok{\#                 intervals}
\CommentTok{\#  {-} stratify = FALSE by default. If TRUE, glm estimations are stratified for}
\CommentTok{\#               each counterfactual scenario defined in abar.}
\CommentTok{\#  {-} estimate.time = FALSE. If TRUE, print a rough estimate of computation time}
\CommentTok{\#  {-} iptw.only = FALSE, useless with g{-}computation}
\CommentTok{\#  {-} variance.method = "ic", computation is faster than with "tmle" which}
\CommentTok{\#                       is useless with g{-}comp: variance estimates rely on}
\CommentTok{\#                       influence curves which cannot be used with g{-}comp because}
\CommentTok{\#                       g{-}computation is not a asymptotically efficient estimator.}
\CommentTok{\#  {-} observation.weights = NULL, can be used to specify individual weights}
\CommentTok{\#  {-} id = subject identifiers, useful in case of clustered structure in the data}

\DocumentationTok{\#\# With a binary outcome, CDE(M=1) = P(Y\_\{A=1,M=0\} = 1) {-} P(Y\_\{A=0,M=0\} = 1)}
\NormalTok{ltmle\_gcomp\_CDE\_M0 }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_death,}
                            \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"edu"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{),}
                            \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"occupation"}\NormalTok{),}
                            \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"death"}\NormalTok{), }\CommentTok{\# binary outcome}
                            \AttributeTok{survivalOutcome =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{Qform =}\NormalTok{ Q\_formulas\_death, }\CommentTok{\# Q formulas}
                            \AttributeTok{gform =}\NormalTok{ g\_formulas, }\CommentTok{\# g formulas}
                            \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                                        \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\# EY\_\{A=1,M=0\} vs EY\_\{A=0,M=0\}}
                            \AttributeTok{rule =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{gbounds =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{), }\CommentTok{\# truncation of g, by default}
                            \AttributeTok{Yrange =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{deterministic.g.function =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{stratify =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{SL.library =} \StringTok{"glm"}\NormalTok{,}
                            \AttributeTok{SL.cvControl =} \FunctionTok{list}\NormalTok{(),}
                            \AttributeTok{estimate.time =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{gcomp =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# should be TRUE for g{-}computation}
                            \AttributeTok{iptw.only =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{deterministic.Q.function =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{,}
                            \AttributeTok{observation.weights =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{id =} \ConstantTok{NULL}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(ltmle\_gcomp\_CDE\_M0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  gcomp 
## Warning: inference for gcomp is not accurate! It is based on TMLE influence curves.
## Call:
## ltmle(data = df_death, Anodes = c("edu", "smoking"), Lnodes = c("phys", 
##     "occupation"), Ynodes = c("death"), survivalOutcome = FALSE, 
##     Qform = Q_formulas_death, gform = g_formulas, abar = list(c(1, 
##         0), c(0, 0)), rule = NULL, gbounds = c(0.01, 1), Yrange = NULL, 
##     deterministic.g.function = NULL, stratify = FALSE, SL.library = "glm", 
##     SL.cvControl = list(), estimate.time = FALSE, gcomp = TRUE, 
##     iptw.only = FALSE, deterministic.Q.function = NULL, variance.method = "ic", 
##     observation.weights = NULL, id = NULL)
## 
## Treatment Estimate:
##    Parameter Estimate:  0.15656 
##     Estimated Std Err:  0.0085093 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.13988, 0.17324) 
## 
## Control Estimate:
##    Parameter Estimate:  0.084535 
##     Estimated Std Err:  0.0063349 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.072118, 0.096951) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.072027 
##     Estimated Std Err:  0.010602 
##               p-value:  1.0947e-11 
##     95% Conf Interval: (0.051247, 0.092808) 
## 
## Relative Risk:
##    Parameter Estimate:  1.852 
##   Est Std Err log(RR):  0.092521 
##               p-value:  2.7185e-11 
##     95% Conf Interval: (1.5449, 2.2203) 
## 
## Odds Ratio:
##    Parameter Estimate:  2.0102 
##   Est Std Err log(OR):  0.10412 
##               p-value:  1.9986e-11 
##     95% Conf Interval: (1.6391, 2.4653)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# With a continuous outcome, CDE(M=1) = E(Y\_\{A=1,M=1\}) {-} E(Y\_\{A=0,M=1\})}
\NormalTok{ltmle\_gcomp\_CDE\_M0 }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_score,}
                            \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"edu"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{),}
                            \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"occupation"}\NormalTok{),}
                            \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"score"}\NormalTok{), }\CommentTok{\# continous outcome}
                            \AttributeTok{survivalOutcome =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{Qform =}\NormalTok{ Q\_formulas\_score, }\CommentTok{\# Q formulas}
                            \AttributeTok{gform =}\NormalTok{ g\_formulas, }\CommentTok{\# g formulas}
                            \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                                        \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\# Y\_\{A=1,M=0\} vs Y\_\{A=0,M=0\}}
                            \AttributeTok{rule =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{gbounds =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{), }\CommentTok{\# by default}
                            \AttributeTok{Yrange =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{deterministic.g.function =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{stratify =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{SL.library =} \StringTok{"glm"}\NormalTok{,}
                            \AttributeTok{SL.cvControl =} \FunctionTok{list}\NormalTok{(),}
                            \AttributeTok{estimate.time =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{gcomp =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# should be TRUE for g{-}computation}
                            \AttributeTok{iptw.only =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{deterministic.Q.function =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{,}
                            \AttributeTok{observation.weights =} \ConstantTok{NULL}\NormalTok{,}
                            \AttributeTok{id =} \ConstantTok{NULL}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(ltmle\_gcomp\_CDE\_M0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  gcomp 
## Warning: inference for gcomp is not accurate! It is based on TMLE influence curves.
## Call:
## ltmle(data = df_score, Anodes = c("edu", "smoking"), Lnodes = c("phys", 
##     "occupation"), Ynodes = c("score"), survivalOutcome = FALSE, 
##     Qform = Q_formulas_score, gform = g_formulas, abar = list(c(1, 
##         0), c(0, 0)), rule = NULL, gbounds = c(0.01, 1), Yrange = NULL, 
##     deterministic.g.function = NULL, stratify = FALSE, SL.library = "glm", 
##     SL.cvControl = list(), estimate.time = FALSE, gcomp = TRUE, 
##     iptw.only = FALSE, deterministic.Q.function = NULL, variance.method = "ic", 
##     observation.weights = NULL, id = NULL)
## 
## Treatment Estimate:
##    Parameter Estimate:  37.537 
##     Estimated Std Err:  0.35058 
##               p-value:  <2e-16 
##     95% Conf Interval: (36.849, 38.224) 
## 
## Control Estimate:
##    Parameter Estimate:  49.669 
##     Estimated Std Err:  0.34282 
##               p-value:  <2e-16 
##     95% Conf Interval: (48.997, 50.341) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  -12.132 
##     Estimated Std Err:  0.48796 
##               p-value:  <2e-16 
##     95% Conf Interval: (-13.089, -11.176)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# in order to apply quasibinomial regressions, ltmle automatically transformed }
\CommentTok{\# the continuous outcome by Y\_transformed = (Y {-} min(Y)) / range(Y)}
\CommentTok{\# so that the range of Y\_transformed is [0,1], }
\CommentTok{\# Then, the results are back{-}transformed.}
\NormalTok{ltmle\_gcomp\_CDE\_M0}\SpecialCharTok{$}\NormalTok{transformOutcome}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
## attr(,"Yrange")
## [1] -49.40414  97.00414
\end{verbatim}

We can see that the results are exactly the same as the previous manual calculation by ICE for the binary outcome. It is slightly different for the continuous outcome (because we did not apply a quasibinomial model on the min-max transformation in the manual calculation).

\section{IPTW estimator of the CDE}\label{iptw-estimator-of-the-cde}

We can express the CDE using coefficients of an MSM, where the MSM's coefficients are estimated by IPTW.

The controlled direct effect is defined as \(\text{CDE}_m= \mathbb{E}(Y_{am}) - \mathbb{E}(Y_{a^*m})\).

Using the following MSM
\begin{equation} 
  \mathbb{E}(Y_{am}) = \alpha_0 + \alpha_A a + \alpha_M m + \alpha_{A \ast M} a \times m
  \label{eq:MSMCDE}
\end{equation}
the controlled direct effect (keeping the mediator constant to the value \(M=m\)) can be expressed using the coefficients of the MSM \eqref{eq:MSMCDE}:
\begin{align*} 
  \text{CDE}_m &= (\alpha_0 + \alpha_A a + \alpha_M m + \alpha_{A \ast M} a \times m) - (\alpha_0 + \alpha_A a^* + \alpha_M m + \alpha_{A \ast M} a^* \times m) \\
  \text{CDE}_m &= \alpha_A(a - a^* ) + \alpha_{A \ast M} \times (a - a^*) \times m
\end{align*}
For a binary exposure \(A\), we have \(\text{CDE}_m=\alpha_A + \alpha_{A \ast M} \times m\).

\subsection{Estimation of the MSM coefficients by IPTW}\label{estimation-of-the-msm-coefficients-by-iptw}

MSM coefficients can be easily estimated using an Inverse Probability of Treatment (IPTW) approach based on weighted regressions.

In order to fit the MSM \eqref{eq:MSMCDE}, we can use a linear regression of the (observed) outcome \(Y\) on the exposure and mediator, weighted by individual stabilized weights \(sw_i\) (\citeproc{ref-vanderweele2009}{VanderWeele 2009}):
\begin{equation} 
  \mathbb{E}\left(Y \mid A,M\right) = \alpha_0 + \alpha_A a + \alpha_M m + \alpha_{A \ast M} a \times m
\end{equation}

where \(sw_i\) is the product of two weights \(sw_i = sw_{A,i} \times sw_{M,i}\),

\(sw_{A,i}=\frac{P(A=a_i)}{P(A=a_i \mid L(0)=l(0)_i)}\) and \(sw_{M,i}=\frac{P(M=m_i \mid A=a_i)}{P(M = m_i \mid A=a_i,L(0)=l(0)_i, L(1)=l(1)_i)}\).

The ``no-unmeasured confounding'' assumption is addressed by the application of weights \(sw_i\), which balances confounders \(L(0)\) relative to the exposure-outcome \(A-Y\) relationship, and balance the set of confounders \(\{L(0),A,L(1)\}\) relative to the mediator-outcome \(M-Y\) relationship.

Below, we estimate the CDE by hand:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# MSM of CDE, estimated by IPTW}
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\DocumentationTok{\#\# 1. Stabilized weight for the exposure sw\_\{A,i\}}
\CommentTok{\# 1a. Estimate g(A=a\_i|L(0)) (denominator of the weight)}
\NormalTok{g\_A\_L }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(edu }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu,}
             \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\CommentTok{\# 1b. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# the predicted probability of the observed treatment g(A = a\_i | L(0)) is :}
\NormalTok{gAi\_L }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gAi\_L[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_A\_L, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]}
\NormalTok{gAi\_L[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(g\_A\_L, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{))[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]}

\CommentTok{\# 1c. Estimate g(A=a\_i) (numerator of the weight)}
\NormalTok{g\_A }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(edu }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\CommentTok{\# 1d. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# the predicted probability of the observed treatment g(A = a\_i) is :}
\NormalTok{gAi }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gAi[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_A, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]}
\NormalTok{gAi[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(g\_A, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{))[df}\SpecialCharTok{$}\NormalTok{edu }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]}

\CommentTok{\# 1e. Calculate the stabilized weight for the exposure A: sw\_\{A,i\}}
\NormalTok{sw\_Ai }\OtherTok{\textless{}{-}}\NormalTok{ gAi }\SpecialCharTok{/}\NormalTok{ gAi\_L}

\DocumentationTok{\#\# 2. Stabilized weight for the mediator sw\_\{M,i\}}
\CommentTok{\# 2a. Estimate g(M=m\_i|L(0),A,L(1)) (denominator of the weight)}
\NormalTok{g\_M\_L }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(smoking }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ phys }\SpecialCharTok{+}\NormalTok{ occupation,}
             \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\CommentTok{\# 2b. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# the predicted probability of the observed treatment g(A = a\_i | L(0)) is :}
\NormalTok{gMi\_L }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gMi\_L[df}\SpecialCharTok{$}\NormalTok{smoking }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_M\_L, }
                                  \AttributeTok{type=}\StringTok{"response"}\NormalTok{)[df}\SpecialCharTok{$}\NormalTok{smoking }\SpecialCharTok{==} \DecValTok{1}\NormalTok{]}
\NormalTok{gMi\_L[df}\SpecialCharTok{$}\NormalTok{smoking }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(g\_M\_L, }
                                       \AttributeTok{type=}\StringTok{"response"}\NormalTok{))[df}\SpecialCharTok{$}\NormalTok{smoking }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]}

\CommentTok{\# 2c. Estimate g(M=m\_i|A) (numerator of the weight)}
\NormalTok{g\_M\_A }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(smoking }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df)}
\CommentTok{\# 2d. Predict each individual\textquotesingle{}s probability of being exposed to her own exposure}
\CommentTok{\# the predicted probability of the observed treatment g(M = m\_i|A) is :}
\NormalTok{gMi\_A }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{gMi\_A[df}\SpecialCharTok{$}\NormalTok{smoking}\SpecialCharTok{==}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(g\_M\_A, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)[df}\SpecialCharTok{$}\NormalTok{smoking}\SpecialCharTok{==}\DecValTok{1}\NormalTok{]}
\NormalTok{gMi\_A[df}\SpecialCharTok{$}\NormalTok{smoking}\SpecialCharTok{==}\DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{predict}\NormalTok{(g\_M\_A, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{))[df}\SpecialCharTok{$}\NormalTok{smoking}\SpecialCharTok{==}\DecValTok{0}\NormalTok{]}
\CommentTok{\# 2e. Calculate the stabilized weight for the mediator M: sw\_\{M,i\}}
\NormalTok{sw\_Mi }\OtherTok{\textless{}{-}}\NormalTok{ gMi\_A }\SpecialCharTok{/}\NormalTok{ gMi\_L}

\DocumentationTok{\#\# 3. Define the individual stabilized weight for the CDE\_m}
\NormalTok{sw\_cde }\OtherTok{\textless{}{-}}\NormalTok{ sw\_Ai }\SpecialCharTok{*}\NormalTok{ sw\_Mi}

\DocumentationTok{\#\# 4. Estimate coefficients of the MSM using a weighted regression E(Y | A, sex)}
\CommentTok{\# a GLM with gaussian family can be applied to estimate risk differences}
\NormalTok{msm\_cde }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ smoking }\SpecialCharTok{+}\NormalTok{ edu}\SpecialCharTok{:}\NormalTok{smoking,}
               \AttributeTok{weights =}\NormalTok{ sw\_cde,}
               \AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{,}
               \AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{coef}\NormalTok{(msm\_cde)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)         edu     smoking edu:smoking 
##  0.08293313  0.07044677  0.11974047  0.14206356
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 5. Estimate CDE for m=0 and for m=1 using the MSM\textquotesingle{}s coefficients}
\NormalTok{CDE\_mis0 }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(msm\_cde)[}\StringTok{"edu"}\NormalTok{] }\SpecialCharTok{+} \DecValTok{0} \SpecialCharTok{*} \FunctionTok{coef}\NormalTok{(msm\_cde)[}\StringTok{"edu:smoking"}\NormalTok{]}
\NormalTok{CDE\_mis0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        edu 
## 0.07044677
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Note: we will see below that the ltmle package use a logistic model for the MSM}
\NormalTok{msm\_cde\_logit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(death }\SpecialCharTok{\textasciitilde{}}\NormalTok{ edu }\SpecialCharTok{+}\NormalTok{ smoking }\SpecialCharTok{+}\NormalTok{ edu}\SpecialCharTok{:}\NormalTok{smoking,}
                     \AttributeTok{weights =}\NormalTok{ sw\_cde,}
                     \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{,}
                     \AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{coef}\NormalTok{(msm\_cde\_logit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)         edu     smoking edu:smoking 
##  -2.4031458   0.6948115   1.0334784   0.3322800
\end{verbatim}

\subsection{IPTW estmation using the ltmle package}\label{iptw-estmation-using-the-ltmle-package}

The \texttt{ltmle} package can be used to estimate Controlled Direct Effects by IPTW, as shown below.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ltmle)}
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\NormalTok{df\_death }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(X, subjid, score))}
\NormalTok{df\_score }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(X, subjid, death))}

\DocumentationTok{\#\# 1) Define Q formulas (Qbar\_L1 and Qbar\_Y functions)}
\DocumentationTok{\#\# (not needed if you only want to apply an IPTW estimation)}
\NormalTok{Q\_formulas\_death }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{phys =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{,}
                      \AttributeTok{death =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + phys + occupation +}
\StringTok{                               edu * smoking"}\NormalTok{) }\CommentTok{\# add interaction}

\DocumentationTok{\#\# 2) Define g formulas (needed for the ltmle package) but they are not used}
\CommentTok{\#    with the g{-}computation estimator}
\NormalTok{g\_formulas }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"edu \textasciitilde{} sex + low\_par\_edu"}\NormalTok{, }
                \StringTok{"smoking \textasciitilde{} sex + low\_par\_edu + edu + phys + occupation"}\NormalTok{)}

\DocumentationTok{\#\# 3) Use the ltmle() function}
\DocumentationTok{\#\# With a binary outcome, CDE(M=1) = P(Y\_\{A=1,M=0\} = 1) {-} P(Y\_\{A=0,M=0\} = 1)}
\NormalTok{ltmle\_iptw\_CDE\_M0 }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_death,}
                           \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"edu"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{),}
                           \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"occupation"}\NormalTok{),}
                           \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"death"}\NormalTok{), }\CommentTok{\# binary outcome}
                           \AttributeTok{survivalOutcome =} \ConstantTok{FALSE}\NormalTok{,}
                           \AttributeTok{Qform =}\NormalTok{ Q\_formulas\_death, }\CommentTok{\# Q formulas}
                           \AttributeTok{gform =}\NormalTok{ g\_formulas, }\CommentTok{\# g formulas}
                           \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                                       \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\# EY\_\{A=1,M=0\} vs EY\_\{A=0,M=0\}}
                           \AttributeTok{rule =} \ConstantTok{NULL}\NormalTok{,}
                           \AttributeTok{gbounds =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{), }\CommentTok{\# truncation of g, by default}
                           \AttributeTok{Yrange =} \ConstantTok{NULL}\NormalTok{,}
                           \AttributeTok{deterministic.g.function =} \ConstantTok{NULL}\NormalTok{,}
                           \AttributeTok{stratify =} \ConstantTok{FALSE}\NormalTok{,}
                           \AttributeTok{SL.library =} \StringTok{"glm"}\NormalTok{, }\CommentTok{\# better to used the SuperLearner}
                           \AttributeTok{SL.cvControl =} \FunctionTok{list}\NormalTok{(),}
                           \AttributeTok{estimate.time =} \ConstantTok{FALSE}\NormalTok{,}
                           \AttributeTok{gcomp =} \ConstantTok{FALSE}\NormalTok{, }
                           \AttributeTok{iptw.only =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# to use only the IPTW estimator}
                           \AttributeTok{deterministic.Q.function =} \ConstantTok{NULL}\NormalTok{,}
                           \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{,}
                           \AttributeTok{observation.weights =} \ConstantTok{NULL}\NormalTok{,}
                           \AttributeTok{id =} \ConstantTok{NULL}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(ltmle\_iptw\_CDE\_M0, }\AttributeTok{estimator =} \StringTok{"iptw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  iptw 
## Call:
## ltmle(data = df_death, Anodes = c("edu", "smoking"), Lnodes = c("phys", 
##     "occupation"), Ynodes = c("death"), survivalOutcome = FALSE, 
##     Qform = Q_formulas_death, gform = g_formulas, abar = list(c(1, 
##         0), c(0, 0)), rule = NULL, gbounds = c(0.01, 1), Yrange = NULL, 
##     deterministic.g.function = NULL, stratify = FALSE, SL.library = "glm", 
##     SL.cvControl = list(), estimate.time = FALSE, gcomp = FALSE, 
##     iptw.only = TRUE, deterministic.Q.function = NULL, variance.method = "ic", 
##     observation.weights = NULL, id = NULL)
## 
## Treatment Estimate:
##    Parameter Estimate:  0.15338 
##     Estimated Std Err:  0.008554 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.13661, 0.17015) 
## 
## Control Estimate:
##    Parameter Estimate:  0.082933 
##     Estimated Std Err:  0.0063406 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.070506, 0.09536) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.070447 
##     Estimated Std Err:  0.010648 
##               p-value:  3.6865e-11 
##     95% Conf Interval: (0.049578, 0.091316) 
## 
## Relative Risk:
##    Parameter Estimate:  1.8494 
##   Est Std Err log(RR):  0.094633 
##               p-value:  8.1651e-11 
##     95% Conf Interval: (1.5363, 2.2263) 
## 
## Odds Ratio:
##    Parameter Estimate:  2.0033 
##   Est Std Err log(OR):  0.10625 
##               p-value:  6.1821e-11 
##     95% Conf Interval: (1.6267, 2.4671)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ltmle\_iptw\_CDE\_M0}\SpecialCharTok{$}\NormalTok{beta.iptw}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)           A 
##  -2.4031458   0.6948115
\end{verbatim}

\section{TMLE estimator of the CDE}\label{tmle-estimator-of-the-cde}

Of course, the main interest of the \texttt{ltmle} package is to apply a TMLE estimator.

As with the G-computation method by iterative conditional expectation, the TMLE procedure relies on the estimation of 2 \(\bar{Q}\) functions:

\begin{itemize}
\tightlist
\item
  \(\bar{Q}_{L(2)}(A=a,M=m) = \mathbb{E}(Y \mid L(0),A,L(1),M)\)
\item
  and \(\bar{Q}_{L(1)} = \mathbb{E}(\hat{\bar{Q}}_{L(2)}(A=a,M=m) \mid L(0),A)\);
\end{itemize}

And as with the IPTW method, the TMLE procedure relies also on the estimation of the 2 treatment mechanisms \(g\):

\begin{itemize}
\tightlist
\item
  \(g_A(L(0)) = P(A=1 \mid L(0))\)
\item
  and \(g_M(L(0),A,L(1)) = P(M=1 \mid L(0),A,L(1))\).
\end{itemize}

\subsection{For binary outcomes}\label{for-binary-outcomes}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\FunctionTok{library}\NormalTok{(ltmle)}
\FunctionTok{library}\NormalTok{(SuperLearner)}
\FunctionTok{library}\NormalTok{(hal9001)}
\DocumentationTok{\#\# 1) Define the formulas for the estimation of the 2 barQ functions and 2 g functions}
\CommentTok{\# Note that it is possible to specify the A*M interaction, if we really want to}
\CommentTok{\# take it into account.}
\DocumentationTok{\#\# Define Q formulas (Qbar\_L1 and Qbar\_Y functions)}
\NormalTok{Qform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{phys =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{,}
           \AttributeTok{death =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + phys + occupation +}
\StringTok{                    edu * smoking"}\NormalTok{)}

\DocumentationTok{\#\# Define the formulas for the estimation of the 2 g function}
\NormalTok{gform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"edu \textasciitilde{} sex + low\_par\_edu"}\NormalTok{,}
           \StringTok{"smoking \textasciitilde{} sex + low\_par\_edu + edu + phys + occupation"}\NormalTok{)}

\DocumentationTok{\#\# The data frame should follow the time{-}ordering of the nodes}
\NormalTok{data\_binary }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \FunctionTok{c}\NormalTok{(sex, low\_par\_edu,}
\NormalTok{                                     edu, phys, occupation,}
\NormalTok{                                     smoking, death))}

\DocumentationTok{\#\# Choose a family of data{-}adaptive algorithms from the SuperLearner package}
\CommentTok{\# Define the SL.interaction.back learner from the SL.step.interaction}
\NormalTok{SL.interaction.back }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(...) \{}
  \FunctionTok{SL.step.interaction}\NormalTok{(..., }\AttributeTok{direction =} \StringTok{"backward"}\NormalTok{)}
\NormalTok{\}}

\CommentTok{\# Define an ad{-}hoc hal learner that can be applied with continous outcomes}
\NormalTok{SL.hal9001.Qbar }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{ (Y, X, newX, family, obsWeights, id, }\AttributeTok{max\_degree =} \DecValTok{2}\NormalTok{, }
                             \AttributeTok{smoothness\_orders =} \DecValTok{1}\NormalTok{, }\AttributeTok{num\_knots =} \DecValTok{5}\NormalTok{, ...) \{}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.matrix}\NormalTok{(X)) }
\NormalTok{    X }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(X)}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(newX) }\SpecialCharTok{\&} \SpecialCharTok{!}\FunctionTok{is.matrix}\NormalTok{(newX)) }
\NormalTok{    newX }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(newX)}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(Y)) }\SpecialCharTok{==} \DecValTok{2}\NormalTok{) \{ }\CommentTok{\# for binomial family}
\NormalTok{    hal\_fit }\OtherTok{\textless{}{-}}\NormalTok{ hal9001}\SpecialCharTok{::}\FunctionTok{fit\_hal}\NormalTok{(}\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }
                                \AttributeTok{weights =}\NormalTok{ obsWeights, }\AttributeTok{id =}\NormalTok{ id, }\AttributeTok{max\_degree =}\NormalTok{ max\_degree, }
                                \AttributeTok{smoothness\_orders =}\NormalTok{ smoothness\_orders, }\AttributeTok{num\_knots =}\NormalTok{ num\_knots, }
\NormalTok{                                ...)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(Y)) }\SpecialCharTok{\textgreater{}} \DecValTok{2}\NormalTok{) \{ }\CommentTok{\# for quasibinomial family}
\NormalTok{    hal\_fit }\OtherTok{\textless{}{-}}\NormalTok{ hal9001}\SpecialCharTok{::}\FunctionTok{fit\_hal}\NormalTok{(}\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{family =} \StringTok{"gaussian"}\NormalTok{, }
                                \AttributeTok{weights =}\NormalTok{ obsWeights, }\AttributeTok{id =}\NormalTok{ id, }\AttributeTok{max\_degree =}\NormalTok{ max\_degree, }
                                \AttributeTok{smoothness\_orders =}\NormalTok{ smoothness\_orders, }\AttributeTok{num\_knots =}\NormalTok{ num\_knots, }
\NormalTok{                                ...)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is.null}\NormalTok{(newX)) \{}
\NormalTok{    pred }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{::}\FunctionTok{predict}\NormalTok{(hal\_fit, }\AttributeTok{new\_data =}\NormalTok{ newX)}
\NormalTok{  \}}
  \ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    pred }\OtherTok{\textless{}{-}}\NormalTok{ stats}\SpecialCharTok{::}\FunctionTok{predict}\NormalTok{(hal\_fit, }\AttributeTok{new\_data =}\NormalTok{ X)}
\NormalTok{  \}}
\NormalTok{  fit }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{object =}\NormalTok{ hal\_fit)}
  \FunctionTok{class}\NormalTok{(fit) }\OtherTok{\textless{}{-}} \StringTok{"SL.hal9001"}
\NormalTok{  out }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{pred =}\NormalTok{ pred, }\AttributeTok{fit =}\NormalTok{ fit)}
  \FunctionTok{return}\NormalTok{(out)}
\NormalTok{\}}
\FunctionTok{environment}\NormalTok{(SL.hal9001.Qbar) }\OtherTok{\textless{}{-}}\FunctionTok{asNamespace}\NormalTok{(}\StringTok{"SuperLearner"}\NormalTok{)}

\DocumentationTok{\#\# Define the SuperLearner library}
\NormalTok{SL.library }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{Q=}\FunctionTok{c}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{,}\StringTok{"SL.glm"}\NormalTok{,}\StringTok{"SL.interaction.back"}\NormalTok{,}\StringTok{"SL.hal9001.Qbar"}\NormalTok{),}
                   \AttributeTok{g=}\FunctionTok{c}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{,}\StringTok{"SL.glm"}\NormalTok{,}\StringTok{"SL.interaction.back"}\NormalTok{,}\StringTok{"SL.hal9001"}\NormalTok{))}


\DocumentationTok{\#\# CDE, setting M=0}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{) }\CommentTok{\# for reproducibility with the SuperLearner}
\NormalTok{CDE\_ltmle\_M0\_death }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data\_binary,}
                            \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"edu"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{),}
                            \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }
                                       \StringTok{"occupation"}\NormalTok{), }\CommentTok{\# intermediate L(1) +/{-} L(0)}
                            \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"death"}\NormalTok{),}
                            \AttributeTok{survivalOutcome =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\# TRUE for time{-}to{-}event outcomes Y}
                            \AttributeTok{Qform =}\NormalTok{ Qform,}
                            \AttributeTok{gform =}\NormalTok{ gform,}
                            \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{\# counterfactual intervention do(A=1,M=0)}
                                        \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\# counterfactual intervention do(A=0,M=0)}
                            \AttributeTok{SL.library =}\NormalTok{ SL.library,}
                            \AttributeTok{estimate.time =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\# estimate computation time?}
                            \AttributeTok{gcomp =} \ConstantTok{FALSE}\NormalTok{,}
                            \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{) }\CommentTok{\# a more robust variance can}
                                                    \CommentTok{\# be estimated with}
                                                    \CommentTok{\# variance.method = "tmle"}
\FunctionTok{summary}\NormalTok{(CDE\_ltmle\_M0\_death, }\AttributeTok{estimator =} \StringTok{"tmle"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  tmle 
## Call:
## ltmle(data = data_binary, Anodes = c("edu", "smoking"), Lnodes = c("phys", 
##     "occupation"), Ynodes = c("death"), survivalOutcome = FALSE, 
##     Qform = Qform, gform = gform, abar = list(c(1, 0), c(0, 0)), 
##     SL.library = SL.library, estimate.time = FALSE, gcomp = FALSE, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  0.15356 
##     Estimated Std Err:  0.0084833 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.13693, 0.17018) 
## 
## Control Estimate:
##    Parameter Estimate:  0.083222 
##     Estimated Std Err:  0.0063304 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.070815, 0.09563) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.070333 
##     Estimated Std Err:  0.010579 
##               p-value:  2.9617e-11 
##     95% Conf Interval: (0.049599, 0.091068) 
## 
## Relative Risk:
##    Parameter Estimate:  1.8451 
##   Est Std Err log(RR):  0.093958 
##               p-value:  7.0611e-11 
##     95% Conf Interval: (1.5348, 2.2182) 
## 
## Odds Ratio:
##    Parameter Estimate:  1.9984 
##   Est Std Err log(OR):  0.1055 
##               p-value:  5.2938e-11 
##     95% Conf Interval: (1.6251, 2.4575)
\end{verbatim}

The controlled direct effect of education on the probability of death, had the mediator been set to 0 for every participant, estimated by TMLE, is 7.03\%, 95\%CI={[}4.96\%, 9.10\%{]}.

Note that an estimation by IPTW is also available (because it relies on the g-functions that have been estimated in the process)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(CDE\_ltmle\_M0\_death, }\AttributeTok{estimator =} \StringTok{"iptw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  iptw 
## Call:
## ltmle(data = data_binary, Anodes = c("edu", "smoking"), Lnodes = c("phys", 
##     "occupation"), Ynodes = c("death"), survivalOutcome = FALSE, 
##     Qform = Qform, gform = gform, abar = list(c(1, 0), c(0, 0)), 
##     SL.library = SL.library, estimate.time = FALSE, gcomp = FALSE, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  0.15344 
##     Estimated Std Err:  0.0085304 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.13672, 0.17016) 
## 
## Control Estimate:
##    Parameter Estimate:  0.082857 
##     Estimated Std Err:  0.0063367 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.070437, 0.095277) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.070583 
##     Estimated Std Err:  0.010626 
##               p-value:  3.0906e-11 
##     95% Conf Interval: (0.049756, 0.091411) 
## 
## Relative Risk:
##    Parameter Estimate:  1.8519 
##   Est Std Err log(RR):  0.094549 
##               p-value:  7.1654e-11 
##     95% Conf Interval: (1.5386, 2.2289) 
## 
## Odds Ratio:
##    Parameter Estimate:  2.0063 
##   Est Std Err log(OR):  0.10614 
##               p-value:  5.3857e-11 
##     95% Conf Interval: (1.6294, 2.4702)
\end{verbatim}

You can check which learner has been used:

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# for the propensity scores g}
\NormalTok{CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{g}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [[1]]$edu
##                              Risk       Coef
## SL.mean_All             0.2409789 0.01398045
## SL.glm_All              0.2359616 0.00000000
## SL.interaction.back_All 0.2359616 0.98601955
## SL.hal9001_All          0.2359785 0.00000000
## 
## [[1]]$smoking
##                              Risk      Coef
## SL.mean_All             0.2429252 0.0000000
## SL.glm_All              0.2220183 0.0000000
## SL.interaction.back_All 0.2220183 0.5880339
## SL.hal9001_All          0.2220520 0.4119661
## 
## 
## [[2]]
## [[2]]$edu
##                              Risk       Coef
## SL.mean_All             0.2409789 0.01398045
## SL.glm_All              0.2359616 0.00000000
## SL.interaction.back_All 0.2359616 0.98601955
## SL.hal9001_All          0.2359785 0.00000000
## 
## [[2]]$smoking
##                              Risk      Coef
## SL.mean_All             0.2429252 0.0000000
## SL.glm_All              0.2220183 0.0000000
## SL.interaction.back_All 0.2220183 0.5880339
## SL.hal9001_All          0.2220520 0.4119661
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# for the models of the outcome (Qbar)}
\NormalTok{CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [[1]]$phys
##                                 Risk      Coef
## SL.mean_All             0.0013590082 0.0000000
## SL.glm_All              0.0001867586 0.2704883
## SL.interaction.back_All 0.0001952437 0.0000000
## SL.hal9001.Qbar_All     0.0001864661 0.7295117
## 
## [[1]]$death
##                              Risk        Coef
## SL.mean_All             0.1905313 0.003179812
## SL.glm_All              0.1667929 0.864927364
## SL.interaction.back_All 0.1668328 0.000000000
## SL.hal9001.Qbar_All     0.1668952 0.131892823
## 
## 
## [[2]]
## [[2]]$phys
##                                 Risk      Coef
## SL.mean_All             4.935728e-04 0.0000000
## SL.glm_All              6.864426e-05 0.2665221
## SL.interaction.back_All 7.175876e-05 0.0000000
## SL.hal9001.Qbar_All     6.853114e-05 0.7334779
## 
## [[2]]$death
##                              Risk        Coef
## SL.mean_All             0.1905313 0.003179812
## SL.glm_All              0.1667929 0.864927364
## SL.interaction.back_All 0.1668328 0.000000000
## SL.hal9001.Qbar_All     0.1668952 0.131892823
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# In practice, the ltmle function estimates an MSM with 2 parameters }
\DocumentationTok{\#\# (which is enough to compare 2 counterfactual scenarios)}
\NormalTok{CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{msm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  glm(formula = formula, family = family, data = data.frame(data, 
##     weights), weights = weights, control = glm.control(maxit = 100))
## 
## Coefficients:
##      S1       S2  
## -2.3993   0.6924  
## 
## Degrees of Freedom: 20000 Total (i.e. Null);  19998 Residual
## Null Deviance:       13560 
## Residual Deviance: 144.9     AIC: NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# You can check the distribution of the g{-}functions to check the }
\DocumentationTok{\#\# positivity assumption}
\FunctionTok{boxplot}\NormalTok{(CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{cum.g[,,}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{_main_files/figure-latex/Psi_CDE_ltmle_bin3-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{boxplot}\NormalTok{(CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{cum.g[,,}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{_main_files/figure-latex/Psi_CDE_ltmle_bin3-2.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Note: cum.g indicates the distribution before truncation at 0.01}
\CommentTok{\#       cum.g.unbounded indicates the distribution after truncation at 0.01}

\DocumentationTok{\#\# The influence curve of the 2 parameters of the MSM are given in the IC matrix}
\CommentTok{\# this is used to calculate the confidence intervals (by delta method)}
\FunctionTok{summary}\NormalTok{(CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{IC)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        S1                 S2          
##  Min.   :-12.0220   Min.   :-93.3038  
##  1st Qu.: -0.4077   1st Qu.: -0.3192  
##  Median : -0.0760   Median :  0.0154  
##  Mean   :  0.0000   Mean   :  0.0000  
##  3rd Qu.:  0.3235   3rd Qu.:  0.3750  
##  Max.   : 93.6256   Max.   : 56.1813
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# the fit$Qstar vector is a list of the fluctuation models}
\DocumentationTok{\#\# used to update the initial Qbar function estimated by g{-}computation}
\CommentTok{\# We can see that each Qbar model have been updated in the TMLE process.}
\NormalTok{CDE\_ltmle\_M0\_death}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{Qstar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $phys
## 
## Call:  glm(formula = formula, family = family, data = data.frame(data, 
##     weights), weights = weights, control = glm.control(maxit = 100))
## 
## Coefficients:
##        S1         S2  
## -0.000820   0.001433  
## 
## Degrees of Freedom: 10000 Total (i.e. Null);  9998 Residual
## Null Deviance:       11.27 
## Residual Deviance: 11.27     AIC: NA
## 
## $death
## 
## Call:  glm(formula = formula, family = family, data = data.frame(data, 
##     weights), weights = weights, control = glm.control(maxit = 100))
## 
## Coefficients:
##        S1         S2  
## -0.026121   0.004088  
## 
## Degrees of Freedom: 4158 Total (i.e. Null);  4156 Residual
## Null Deviance:       2806 
## Residual Deviance: 2806  AIC: NA
\end{verbatim}

\subsection{For continuous outcomes}\label{for-continuous-outcomes}

As previously, for continuous outcomes, the \texttt{ltmle} package transforms the outcome on a 0 to 1 continuous scale, \(Y_\text{transformed} = \frac{Y - \min(Y)}{\max(Y) - \min(Y)}\), so that quasi-binomial parametric models can be used in the computation procedure. Mean predictions are then back-transformed on the original scale.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Define the data set with the continuous outcome score}
\NormalTok{data\_continuous }\OtherTok{\textless{}{-}} \FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \FunctionTok{c}\NormalTok{(sex, low\_par\_edu,}
\NormalTok{                                         edu, phys, occupation,}
\NormalTok{                                         smoking, score))}
\DocumentationTok{\#\# Replace the Qbar function }
\DocumentationTok{\#\# (the 2d formula should be named score instead of death)}
\NormalTok{Qform }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{phys =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + edu"}\NormalTok{,}
           \AttributeTok{score =} \StringTok{"Q.kplus1 \textasciitilde{} sex + low\_par\_edu + phys + occupation +}
\StringTok{                               edu * smoking"}\NormalTok{) }\CommentTok{\# add interaction}
\DocumentationTok{\#\# SuperLearner library}
\NormalTok{SL.library }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{Q=}\FunctionTok{c}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{,}\StringTok{"SL.glm"}\NormalTok{,}\StringTok{"SL.interaction.back"}\NormalTok{,}\StringTok{"SL.hal9001.Qbar"}\NormalTok{),}
                   \AttributeTok{g=}\FunctionTok{c}\NormalTok{(}\StringTok{"SL.mean"}\NormalTok{,}\StringTok{"SL.glm"}\NormalTok{,}\StringTok{"SL.interaction.back"}\NormalTok{,}\StringTok{"SL.hal9001"}\NormalTok{))}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\DocumentationTok{\#\# CDE, setting M=0}
\NormalTok{CDE\_ltmle\_M0\_score }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ data\_continuous,}
                            \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"edu"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{),}
                            \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"occupation"}\NormalTok{), }
                            \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"score"}\NormalTok{),}
                            \AttributeTok{survivalOutcome =} \ConstantTok{FALSE}\NormalTok{, }
                            \AttributeTok{Qform =}\NormalTok{ Qform,}
                            \AttributeTok{gform =}\NormalTok{ gform,}
                            \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{\# do(A=1,M=0)}
                                        \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\#  do(A=0,M=0)}
                            \AttributeTok{SL.library =}\NormalTok{ SL.library,}
                            \AttributeTok{estimate.time =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\# estimate computation time?}
                            \AttributeTok{gcomp =} \ConstantTok{TRUE}\NormalTok{,}
                            \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{)}
\FunctionTok{summary}\NormalTok{(CDE\_ltmle\_M0\_score)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  gcomp 
## Warning: inference for gcomp is not accurate! It is based on TMLE influence curves.
## Call:
## ltmle(data = data_continuous, Anodes = c("edu", "smoking"), Lnodes = c("phys", 
##     "occupation"), Ynodes = c("score"), survivalOutcome = FALSE, 
##     Qform = Qform, gform = gform, abar = list(c(1, 0), c(0, 0)), 
##     SL.library = SL.library, estimate.time = FALSE, gcomp = TRUE, 
##     variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  37.536 
##     Estimated Std Err:  0.34926 
##               p-value:  <2e-16 
##     95% Conf Interval: (36.852, 38.221) 
## 
## Control Estimate:
##    Parameter Estimate:  49.66 
##     Estimated Std Err:  0.34266 
##               p-value:  <2e-16 
##     95% Conf Interval: (48.989, 50.332) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  -12.124 
##     Estimated Std Err:  0.4869 
##               p-value:  <2e-16 
##     95% Conf Interval: (-13.078, -11.17)
\end{verbatim}

The controlled direct effect of education on the score outcome, had the mediator been set to 0 for every participant, estimated by TMLE is -12.12, 95\%CI={[}-13.08, -11.17{]}.

\chapter{Estimate rNDE and rNIE by double robust estimators}\label{estimate-rnde-and-rnie-by-double-robust-estimators}

A very general presentation of randomized Natural Direct and Indirect effects is described in (\citeproc{ref-Diaz2023}{Iván Díaz, Williams, and Rudolph 2023}).

The causal estimands are:
\begin{align*}
  rNDE &= \mathbb{E}\left(Y_{A=1,G_{A=0}}\right) - \mathbb{E}\left(Y_{A=0,G_{A=0}}\right) \\
  rNIE &= \mathbb{E}\left(Y_{A=1,G_{A=1}}\right) - \mathbb{E}\left(Y_{A=1,G_{A=0}}\right) \\
\end{align*}

It is possible to identify the causal estimand \(\theta = \mathbb{E}\left(Y_{a^\prime,G_{a^*}} \right)\) by the following statistical estimand:
\begin{align*}
  \theta &= \mathbb{E}\left[ \sum_{m \in M} \varphi(a^\prime,m) \times \lambda(a^*,m) \right], \text{ where}\\
  \varphi(a^\prime,m) &= \sum_{l(0),l(1)} \mathbb{E}\left(Y \mid l(0),A=a^\prime,l(1),m\right)\times P(L(1)=l(1) \mid l(0),a^\prime) \times P(L(0)=l(0) \\
  \lambda(a^*,m) &= \sum_{l(0),l(1)} P\left(M=m,L(1)=l(1) \mid A=a^*, l(0) \right) \times P(L(0)=l(0)) 
\end{align*}

\section{G-computation algorithm to compute randomized Natural Direct and Indirect effects}\label{g-computation-algorithm-to-compute-randomized-natural-direct-and-indirect-effects}

A general g-computation algorithm that can be used to estimate randomized (interventional) Natural Direct and Indirect Effects is described below:

The components \(\varphi(a^\prime,m)\) and \(\lambda(a^*,m)\) can be estimated using 2 \(Q\) functions that we need to estimate:
\begin{equation*}
  \theta = \mathbb{E}\left(Y_{a^\prime,G_{a^*}} \right) = \sum_{m} Q_{L,0}(a^\prime,m) \times Q_{M,0}(a^*,m)
\end{equation*}
The first component \(Q_{L,0}(m)\) for a given value of \(m\in \{0,1\}\), is estimated by iterative conditional expectation:
\begin{align*}
  Q_{L,3} &= Y \\
  Q_{L,2}(m) &= \mathbb{E}\left(Q_{L,3} \mid L(0),A,L(1),M=m\right) \\
  Q_{L,1}(a^\prime,m) &= \mathbb{E}\left(Q_{L,2} \mid L(0),A=a^\prime\right) \\
  Q_{L,0}(a^\prime,m) &= \mathbb{E}\left(Q_{L,1}\right) = \varphi(a^\prime,m)
\end{align*}
The second component \(Q_{M,0}(m)\) for the same value \(m\) is also estimated by iterative conditional expectation:
\begin{align*}
  Q_{M,1}(a^*,m) &= \mathbb{E}\left(\mathbb{I}(M=m) \mid L(0), A=a^* \right) \\
  Q_{M,0}(a^*,m) &= \mathbb{E}\left(Q_{M,1}\right) = \lambda(a^*,m)
\end{align*}

Applied to our example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}
\DocumentationTok{\#\# We need to estimate theta under 3 scenarios: }
\NormalTok{scenarios }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{a\_prime =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
                        \AttributeTok{a\_star =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }
                        \AttributeTok{theta =} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\DecValTok{3}\NormalTok{))}
\DocumentationTok{\#\# For EY\_\{A=0,G\_\{A=0\}\} (ie: a\textquotesingle{} = 0, a* = 0)}
\ControlFlowTok{for}\NormalTok{(s }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)\{}
\NormalTok{  Q\_L0\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{() }\CommentTok{\# we will estimate 2 Q\_L0 (one for each value of M)}
\NormalTok{  Q\_M0\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{() }\CommentTok{\# we will estimate 2 Q\_M0 (one for each value of M)}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{) \{}
    \CommentTok{\# Set the value of the mediator}
\NormalTok{    m }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{{-}} \DecValTok{1}
    \CommentTok{\# Estimate Q\_L0 under A=a\textquotesingle{} and M=m}
\NormalTok{    Q\_L3 }\OtherTok{\textless{}{-}}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death}
\NormalTok{    df\_m }\OtherTok{\textless{}{-}}\NormalTok{ df}
\NormalTok{    df\_m}\SpecialCharTok{$}\NormalTok{smoking }\OtherTok{\textless{}{-}}\NormalTok{ m}
\NormalTok{    Q\_L2 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(}\FunctionTok{glm}\NormalTok{(Q\_L3 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ phys }\SpecialCharTok{+}\NormalTok{ occupation }\SpecialCharTok{+} 
\NormalTok{                          edu }\SpecialCharTok{*}\NormalTok{ smoking,}
                        \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df),}
                    \AttributeTok{newdata =}\NormalTok{ df\_m,}
                    \AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{    df\_aprime }\OtherTok{\textless{}{-}}\NormalTok{ df}
\NormalTok{    df\_aprime}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_prime[s]}
\NormalTok{    Q\_L1 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(}\FunctionTok{glm}\NormalTok{(Q\_L2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu,}
                        \AttributeTok{family =} \StringTok{"quasibinomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df),}
                    \AttributeTok{newdata =}\NormalTok{ df\_aprime,}
                    \AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{    Q\_L0 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Q\_L1)}
\NormalTok{    Q\_L0\_list[i] }\OtherTok{\textless{}{-}}\NormalTok{ Q\_L0}
    
    \CommentTok{\# Estimate Q\_M0 under M=m}
\NormalTok{    df\_astar }\OtherTok{\textless{}{-}}\NormalTok{ df}
\NormalTok{    df\_astar}\SpecialCharTok{$}\NormalTok{edu }\OtherTok{\textless{}{-}}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star[s]}
\NormalTok{    Q\_M1 }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(}\FunctionTok{glm}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(smoking }\SpecialCharTok{==}\NormalTok{ m) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex }\SpecialCharTok{+}\NormalTok{ low\_par\_edu }\SpecialCharTok{+}\NormalTok{ edu,}
                        \AttributeTok{family =} \StringTok{"binomial"}\NormalTok{, }\AttributeTok{data =}\NormalTok{ df),}
                    \AttributeTok{newdata =}\NormalTok{ df\_astar,}
                    \AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{    Q\_M0 }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(Q\_M1)}
\NormalTok{    Q\_M0\_list[i] }\OtherTok{\textless{}{-}}\NormalTok{ Q\_M0}
\NormalTok{  \}}
  \CommentTok{\# calculate theta for the scenario s}
\NormalTok{  scenarios}\SpecialCharTok{$}\NormalTok{theta[s] }\OtherTok{\textless{}{-}}\NormalTok{ ((Q\_L0\_list[[}\DecValTok{1}\NormalTok{]] }\SpecialCharTok{*}\NormalTok{ Q\_M0\_list[[}\DecValTok{1}\NormalTok{]]) }\SpecialCharTok{+} 
\NormalTok{                           (Q\_L0\_list[[}\DecValTok{2}\NormalTok{]] }\SpecialCharTok{*}\NormalTok{ Q\_M0\_list[[}\DecValTok{2}\NormalTok{]]))}
\NormalTok{\}}

\DocumentationTok{\#\# The rNDE = EY(A=1,G\_A=0) {-} EY(A=0,G\_A=0)}
\NormalTok{rNDE }\OtherTok{\textless{}{-}}\NormalTok{ (scenarios}\SpecialCharTok{$}\NormalTok{theta[scenarios}\SpecialCharTok{$}\NormalTok{a\_prime }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{{-}} 
\NormalTok{           scenarios}\SpecialCharTok{$}\NormalTok{theta[scenarios}\SpecialCharTok{$}\NormalTok{a\_prime }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
\NormalTok{rNDE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1370682
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The rNIE = EY(A=1,G\_A=1) {-} EY(A=1,G\_A=0)}
\NormalTok{rNIE }\OtherTok{\textless{}{-}}\NormalTok{ (scenarios}\SpecialCharTok{$}\NormalTok{theta[scenarios}\SpecialCharTok{$}\NormalTok{a\_prime }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} 
\NormalTok{           scenarios}\SpecialCharTok{$}\NormalTok{theta[scenarios}\SpecialCharTok{$}\NormalTok{a\_prime }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
\NormalTok{rNIE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.04941265
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The total effect rTE = EY(A=1,G\_A=1) {-} EY(A=0,G\_A=0)}
\NormalTok{rTE }\OtherTok{\textless{}{-}}\NormalTok{ (scenarios}\SpecialCharTok{$}\NormalTok{theta[scenarios}\SpecialCharTok{$}\NormalTok{a\_prime }\SpecialCharTok{==} \DecValTok{1} \SpecialCharTok{\&}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}} 
\NormalTok{           scenarios}\SpecialCharTok{$}\NormalTok{theta[scenarios}\SpecialCharTok{$}\NormalTok{a\_prime }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ scenarios}\SpecialCharTok{$}\NormalTok{a\_star }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
\NormalTok{rTE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1864809
\end{verbatim}

\section{Packages to get double robust estimations}\label{packages-to-get-double-robust-estimations}

The \texttt{medoutcon} \href{https://github.com/nhejazi/medoutcon}{package} (\citeproc{ref-Hejazi2022}{Hejazi, Rudolph, and Díaz 2022}),(\citeproc{ref-Diaz2020}{I. Díaz et al. 2020}) enables the estimation of Randomized/Interventional Direct and Indirect Effects (analogues of the Natural direct and indirect effects) by one-step estimation or TMLE. In this package, the one-step estimator relies on ``cross-fitting'' and the TMLE relies on cross-validation.

More practical details can be found in the \href{https://codex.nimahejazi.org/ser2024_mediation_workshop/}{Materials for the workshop ``Modern Causal Mediation Analysis'' at the 2024 Society for Epidemiologic Research (SER) annual meeting in Austin, TX} and the \href{https://codex.nimahejazi.org/ser2025_mediation_workshop/}{Materials for the workshop ``Modern Causal Mediation Analysis'' at the 2025 Society for Epidemiologic Research (SER) annual meeting in Boston, MA}.

This package is associated with the \texttt{tlverse} \href{https://tlverse.org/tlverse-handbook/}{ecosystem} which has been developed for applying Targeted Learning methodology in practice. To use the \texttt{medoutcon} package, we will need:

\begin{itemize}
\tightlist
\item
  the \texttt{sl3} \href{https://github.com/tlverse/sl3}{package} (to implement SuperLearning)
\item
  and the Highly-adaptive lasso \texttt{hal9001} \href{https://cran.r-project.org/web/packages/hal9001/index.html}{package} to estimate some functions of interest.
\end{itemize}

Note that the \texttt{medoutcon} package can deal with multiple mediators, but only a single binary intermediate confounder \(L(1)\). Other alternative packages have been developed (but usually still at a development stage):

\begin{itemize}
\tightlist
\item
  For causal structures with a low-dimensional mediator (1 binary or categorical variable) and high-dimensional intermediate confounding (with several variables, possibly continuous), the \texttt{lcm} \href{https://github.com/nt-williams/lcm}{package} can be used. This package was mainly developed to deal with longitudinal causal mediation (lcm), with repeated waves of ``exposure -\textgreater{} intermediate confounder -\textgreater{} mediator'' structures.
\item
  For causal structures with multiple mediators and multiple intermediate confounders, the \texttt{HDmediation} \href{https://github.com/nt-williams/HDmediation}{package} could be used instead.
\end{itemize}

Below, we apply the one-step estimator to our data with 1 intermediate confounders affected by the exposure. Using the HAL algorithm will deal with possible exposure-interaction terms.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# remotes::install\_github("nhejazi/medoutcon")}
\CommentTok{\# remotes::install\_github("nhejazi/medoutcon", INSTALL\_opts=c("{-}{-}no{-}multiarch"))}
\CommentTok{\# https://arxiv.org/pdf/1912.09936}
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df.csv"}\NormalTok{)}

\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## -- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --
## v dplyr     1.1.4     v readr     2.1.5
## v forcats   1.0.1     v stringr   1.5.2
## v ggplot2   4.0.0     v tibble    3.3.0
## v lubridate 1.9.4     v tidyr     1.3.1
## v purrr     1.0.4     
## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x purrr::accumulate() masks foreach::accumulate()
## x dplyr::filter()     masks stats::filter()
## x dplyr::lag()        masks stats::lag()
## x dplyr::sym()        masks ggplot2::sym(), r2symbols::sym()
## x purrr::when()       masks foreach::when()
## i Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(sl3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Registered S3 methods overwritten by 'lava':
##   method           from  
##   print.estimate   EValue
##   summary.estimate EValue
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(medoutcon)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## medoutcon v0.2.4: Efficient Natural and Interventional Causal Mediation Analysis
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(hal9001)}

\DocumentationTok{\#\# Because the medoutcon package can only deal with 1 intermediate numeric confounder,}
\DocumentationTok{\#\# we will use an example where:}
\DocumentationTok{\#\#  {-} the intermediate confounder is "occupation"}
\DocumentationTok{\#\#  {-} the mediators of interest are "smoking" and "physical activity"}


\DocumentationTok{\#\# 1) binary outcome }
\CommentTok{\# {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-} \#}
\DocumentationTok{\#\#\# Compute one{-}step estimate of the randomized natural direct effect}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{os\_de }\OtherTok{\textless{}{-}} \FunctionTok{medoutcon}\NormalTok{(}\AttributeTok{W =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{, }\StringTok{"low\_par\_edu"}\NormalTok{)], }\CommentTok{\# matrix of L(0)}
                   \AttributeTok{A =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu, }\CommentTok{\# numeric vector of the exposure}
                   \AttributeTok{Z =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{occupation, }\CommentTok{\# numeric vector L(1) (only 1 variable)}
                   \AttributeTok{M =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{)], }\CommentTok{\# numeric vector or matrix}
                   \AttributeTok{Y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death, }\CommentTok{\# numeric vector}
                   \AttributeTok{effect =} \StringTok{"direct"}\NormalTok{,}
                   \AttributeTok{b\_learners =}\NormalTok{ sl3}\SpecialCharTok{::}\NormalTok{Lrnr\_hal9001}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(), }\CommentTok{\# outcome regression}
                   \AttributeTok{estimator =} \StringTok{"onestep"}\NormalTok{)}
\NormalTok{os\_de}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Interventional Direct Effect
## Estimator: onestep
## Estimate: 0.135
## Std. Error: 0.008
## 95% CI: [0.119, 0.151]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The output gives a list containing:}
\CommentTok{\#  {-} theta = the estimand}
\CommentTok{\#  {-} var = variance of the estimand}
\CommentTok{\#  {-} eif = the efficient influence curve}
\NormalTok{os\_de}\SpecialCharTok{$}\NormalTok{theta}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1347152
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(os\_de}\SpecialCharTok{$}\NormalTok{var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.008076797
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(os\_de}\SpecialCharTok{$}\NormalTok{eif) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(df))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.008076797
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# Compute one{-}step estimate of the randomized natural indirect effect}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{os\_ie }\OtherTok{\textless{}{-}} \FunctionTok{medoutcon}\NormalTok{(}\AttributeTok{W =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{,}\StringTok{"low\_par\_edu"}\NormalTok{)], }\CommentTok{\#matrix of baseline L(0)}
                   \AttributeTok{A =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu, }\CommentTok{\# numeric vector of the exposure}
                   \AttributeTok{Z =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{occupation, }\CommentTok{\# numeric vector L(1) (only 1 variable)}
                   \AttributeTok{M =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{)], }\CommentTok{\# numeric vector or matrix}
                   \AttributeTok{Y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death, }\CommentTok{\# numeric vector}
                   \AttributeTok{effect =} \StringTok{"indirect"}\NormalTok{,}
                   \AttributeTok{b\_learners =}\NormalTok{ sl3}\SpecialCharTok{::}\NormalTok{Lrnr\_hal9001}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(), }\CommentTok{\# outcome regression}
                   \AttributeTok{estimator =} \StringTok{"onestep"}\NormalTok{)}
\NormalTok{os\_ie}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Interventional Indirect Effect
## Estimator: onestep
## Estimate: 0.05
## Std. Error: 0.004
## 95% CI: [0.043, 0.057]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# In order to estimate the total effect TE = EY\_\{A=1,M(A=1) \}{-} EY\_\{A=0,M(A=0)\}}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{EY\_1M1 }\OtherTok{\textless{}{-}} \FunctionTok{medoutcon}\NormalTok{(}\AttributeTok{W =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{,}\StringTok{"low\_par\_edu"}\NormalTok{)], }\CommentTok{\#matrix of baseline L(0)}
                    \AttributeTok{A =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu, }\CommentTok{\# numeric vector of the exposure}
                    \AttributeTok{Z =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{occupation, }\CommentTok{\# numeric vector L(1) (only 1 variable)}
                    \AttributeTok{M =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{)], }\CommentTok{\# numeric vector or matrix}
                    \AttributeTok{Y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death, }\CommentTok{\# numeric vector}
                    \AttributeTok{contrast =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{),}
                    \AttributeTok{b\_learners =}\NormalTok{ sl3}\SpecialCharTok{::}\NormalTok{Lrnr\_hal9001}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(), }\CommentTok{\# outcome regression}
                    \AttributeTok{estimator =} \StringTok{"onestep"}\NormalTok{)}
\NormalTok{EY\_1M1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Counterfactual TSM
## Contrast: A = 1, M(A = 1)
## Estimator: onestep
## Estimate: 0.328
## Std. Error: 0.006
## 95% CI: [0.316, 0.34]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{EY\_0M0 }\OtherTok{\textless{}{-}} \FunctionTok{medoutcon}\NormalTok{(}\AttributeTok{W =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{,}\StringTok{"low\_par\_edu"}\NormalTok{)], }\CommentTok{\#matrix of baseline L(0)}
                    \AttributeTok{A =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{edu, }\CommentTok{\# numeric vector of the exposure}
                    \AttributeTok{Z =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{occupation, }\CommentTok{\# numeric vector L(1) (only 1 variable)}
                    \AttributeTok{M =}\NormalTok{ df[,}\FunctionTok{c}\NormalTok{(}\StringTok{"phys"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{)], }\CommentTok{\# numeric vector or matrix}
                    \AttributeTok{Y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{death, }\CommentTok{\# numeric vector}
                    \AttributeTok{contrast =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{),}
                    \AttributeTok{b\_learners =}\NormalTok{ sl3}\SpecialCharTok{::}\NormalTok{Lrnr\_hal9001}\SpecialCharTok{$}\FunctionTok{new}\NormalTok{(), }\CommentTok{\# outcome regression}
                    \AttributeTok{estimator =} \StringTok{"onestep"}\NormalTok{)}
\NormalTok{EY\_0M0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Counterfactual TSM
## Contrast: A = 0, M(A = 0)
## Estimator: onestep
## Estimate: 0.143
## Std. Error: 0.006
## 95% CI: [0.132, 0.154]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# The total effect (global effect can be calculated by:}
\NormalTok{rTE }\OtherTok{\textless{}{-}}\NormalTok{ EY\_1M1}\SpecialCharTok{$}\NormalTok{theta }\SpecialCharTok{{-}}\NormalTok{ EY\_0M0}\SpecialCharTok{$}\NormalTok{theta}
\NormalTok{rTE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1849101
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# se}
\NormalTok{se\_rTE }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(EY\_1M1}\SpecialCharTok{$}\NormalTok{eif }\SpecialCharTok{{-}}\NormalTok{ EY\_0M0}\SpecialCharTok{$}\NormalTok{eif) }\SpecialCharTok{/} \FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{se\_rTE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.008343679
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# 95\%CI}
\FunctionTok{c}\NormalTok{(rTE }\SpecialCharTok{{-}} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_rTE,}
\NormalTok{  rTE }\SpecialCharTok{+} \FunctionTok{qnorm}\NormalTok{(}\FloatTok{0.975}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_rTE)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1685568 0.2012634
\end{verbatim}

Beware, in simulations, the TMLE estimator of the \texttt{medoutcon} function seemed to be biased compared to the one-step estimator.

In 2025, there are some packages same can enable us to get double robust estimation of randomized direct and indirect effects. However, most of them are still in development so it might be a better to test them on simulations before implementing them in real data analyses.

\chapter{\texorpdfstring{\texttt{ltmle} package with interval censored survival data}{ltmle package with interval censored survival data}}\label{ltmle-package-with-interval-censored-survival-data}

\section{Setting}\label{setting}

The \texttt{ltmle} package can be used to estimate a cumulative risk, with interval censored survival data.

Here we simulate a simple example, based on 2 intervals between 3 visits.

\begin{itemize}
\tightlist
\item
  baseline confounders \(L(0)\) and the exposure of interest \(A\) is measured at visit 1.
\item
  intermediate confounders \(L(1)\) and the mediator \(M\) are measured at visit 2. Death and censoring can occur before the mediator:
\item
  \(Y(1)\) and \(Y(2)\) are occurences of death between visits 1 and 2, and visits 2 and 3.
\item
  \(C(1)\) and \(C(2)\) are censoring occuring before visit 2 and before visite 3, respectively. They will be considered as exposure variables (treatment mechanisms) and counterfactual scenarios will be emulated under ``no censoring''. Censoring can be informative (influenced by previous variables in the system).
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{./images/DAG_survival} 

}

\caption{DAG with interval censored survival data}\label{fig:figDAG2}
\end{figure}

In this example, we simulate the exposure and the mediator as 3-level categorical variables. In order to implement the \texttt{ltmle} function, each one needs to be recoded by 2 dummy variables. For example:

\begin{itemize}
\tightlist
\item
  The exposure \(A(1)= \{0,1,2\}\) can be recoded by 2 dummy variables (\(A(1)_1\) and \(A(1)_2\)):
  \begin{align*}
  A(1)_1 &= \mathbb{I}(A(1) = 1) \\
  A(1)_2 &= \mathbb{I}(A(1) = 2) \\
    \end{align*}
  and the distribution \(P(a(1)) = P(a(1)_1, a(1)_2) = P(a(1)_1) \times (P(a(1)_2 \mid a(1)_1)\). We also know that if the first dummy variable \(A(1)_1 = 1\), then \(A(1)_2 = 0\) deterministically. However, if \(A(1)_1 = 0\), then we can apply the conditional probability \(P(A(1)_2 = 1 \mid L(0))\).
\end{itemize}

\section{Data generating function}\label{data-generating-function}

Here is a example of a function simulating data corresponding to this DAG.

Note, in this example, we did not add ``Exposures \(\times\) mediator'' interaction terms in the 2 outcome models, so that the controlled direct effects is expected to be independent of the value \(m\) chosen, when setting \(M=m\) for Controlled Direct Effects.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}

\DocumentationTok{\#\# Data generating function {-}{-}{-}{-}}
\NormalTok{GenerateData.CDE }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(N) \{ }
  \CommentTok{\# rexpit function}
\NormalTok{  rexpit }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{ (x) }\FunctionTok{rbinom}\NormalTok{(}\FunctionTok{length}\NormalTok{(x), }\DecValTok{1}\NormalTok{, }\FunctionTok{plogis}\NormalTok{(x))}
  
  \CommentTok{\# baseline confounders L0}
\NormalTok{  L0\_1 }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(N, }\AttributeTok{size =} \DecValTok{1}\NormalTok{, }\AttributeTok{prob =} \FloatTok{0.45}\NormalTok{) }
\NormalTok{  L0\_2 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.6}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1) }
  
  \CommentTok{\# exposure A: treatment}
\NormalTok{  A1\_1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.9}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2)}
\NormalTok{  A1\_2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(A1\_1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
                 \DecValTok{0}\NormalTok{,}
                 \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.8}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2))}
  
  \CommentTok{\# censoring C1}
\NormalTok{  C1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.03}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.4}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.4}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2 }\SpecialCharTok{+} 
                 \FunctionTok{log}\NormalTok{(}\FloatTok{1.1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.4}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_2)}
  
  \CommentTok{\# death Y1}
\NormalTok{  Y1 }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1  }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2 }\SpecialCharTok{+} 
                 \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_1 }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{3}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_2)  }
  
  \DocumentationTok{\#\#\# intermediate counfounders L1}
\NormalTok{  L1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
               \ConstantTok{NA}\NormalTok{,}
               \FunctionTok{rnorm}\NormalTok{(N, }\AttributeTok{mean =} \DecValTok{50} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{5} \SpecialCharTok{*}\NormalTok{ L0\_1) }\SpecialCharTok{+} 
\NormalTok{                       (}\SpecialCharTok{{-}}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ L0\_2) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{4} \SpecialCharTok{*}\NormalTok{ A1\_1) }\SpecialCharTok{+}\NormalTok{ (}\DecValTok{10} \SpecialCharTok{*}\NormalTok{ A1\_2),}
                     \AttributeTok{sd =} \DecValTok{15}\NormalTok{))}

  \CommentTok{\# mediator M2: continue treatment}
\NormalTok{  M2\_1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }
                 \ConstantTok{NA}\NormalTok{, }
                 \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{0.9}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]  }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.3}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.6}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_2[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.02}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]))}
\NormalTok{  M2\_2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, N)}
\NormalTok{  M2\_2[Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{  M2\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  M2\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.4}\NormalTok{) }\SpecialCharTok{+} 
                                        \FunctionTok{log}\NormalTok{(}\FloatTok{0.9}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{]  }\SpecialCharTok{+} 
                                        \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                        \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                        \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                        \FunctionTok{log}\NormalTok{(}\FloatTok{1.03}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ M2\_1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}
  
  \CommentTok{\# censoring C2}
\NormalTok{  C2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, N)}
\NormalTok{  C2[Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{  C2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  C2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.03}\NormalTok{) }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.4}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.4}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.05}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.01}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ M2\_1[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                                    \FunctionTok{log}\NormalTok{(}\FloatTok{1.4}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ M2\_2[Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])}

  \CommentTok{\# death Y2}
\NormalTok{  Y2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, N)}
\NormalTok{  Y2[Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  Y2[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{rexpit}\NormalTok{(}\FunctionTok{qlogis}\NormalTok{(}\FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\FloatTok{1.2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L0\_2[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ A1\_2[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.01}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ L1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} 
                          \FunctionTok{log}\NormalTok{(}\FloatTok{1.5}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ M2\_1[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{] }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ M2\_2[Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{])  }
                               
\NormalTok{  df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{L0\_1 =}\NormalTok{ L0\_1, }\AttributeTok{L0\_2 =}\NormalTok{ L0\_2,}
                   \AttributeTok{A1\_1 =}\NormalTok{ A1\_1, }\AttributeTok{A1\_2 =}\NormalTok{ A1\_2, C1,}
                   \AttributeTok{Y1 =}\NormalTok{ Y1, }\AttributeTok{L1 =}\NormalTok{ L1,}
                   \AttributeTok{M2\_1 =}\NormalTok{ M2\_1, }\AttributeTok{M2\_2 =}\NormalTok{ M2\_2, C2,}
                   \AttributeTok{Y2 =}\NormalTok{ Y2)}
  
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{Y1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, df}\SpecialCharTok{$}\NormalTok{Y1)}
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{L1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, df}\SpecialCharTok{$}\NormalTok{L1)}
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{M2\_1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, df}\SpecialCharTok{$}\NormalTok{M2\_1)}
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{M2\_2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, df}\SpecialCharTok{$}\NormalTok{M2\_2)}
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{C2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, df}\SpecialCharTok{$}\NormalTok{C2)}
\NormalTok{  df}\SpecialCharTok{$}\NormalTok{Y2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{C2 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\ConstantTok{NA}\NormalTok{, df}\SpecialCharTok{$}\NormalTok{Y2)}

  \FunctionTok{return}\NormalTok{(df)}
\NormalTok{\}}

\DocumentationTok{\#\# Generate 1 data frame, named df2 {-}{-}{-}{-}}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{df2 }\OtherTok{\textless{}{-}} \FunctionTok{GenerateData.CDE}\NormalTok{(}\AttributeTok{N =} \DecValTok{10000}\NormalTok{)}
\FunctionTok{write.csv2}\NormalTok{(df2, }\StringTok{"data/df2.csv"}\NormalTok{)}

\DocumentationTok{\#\# Import data df2}
\NormalTok{df2 }\OtherTok{\textless{}{-}} \FunctionTok{read.csv2}\NormalTok{(}\StringTok{"data/df2.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Inspect the data generated}\label{inspect-the-data-generated}

Let's inspect the data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(df2)}
\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{with}\NormalTok{(}\FunctionTok{table}\NormalTok{(A1\_1, A1\_2)) }\CommentTok{\# distribution of the exposure}

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summary}\NormalTok{() }\CommentTok{\# 519 censored after C1}

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summary}\NormalTok{() }\CommentTok{\# distribution of variables uncensored after C1}

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summary}\NormalTok{() }\CommentTok{\# among uncensored participants at C1, 1319 death at Y1}

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summary}\NormalTok{() }\CommentTok{\# distribution of variables uncensored at C1 and alive at Y1}
            

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C2 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summary}\NormalTok{() }\CommentTok{\# 754 censored at C2}

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ Y1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ C2 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summary}\NormalTok{() }\CommentTok{\# distribution of variable alive at Y1 and uncensored at C2}

\NormalTok{df2 }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{subset}\NormalTok{(}\AttributeTok{subset =}\NormalTok{ (C1 }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ Y1 }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{with}\NormalTok{(}\FunctionTok{table}\NormalTok{(M2\_1, M2\_2)) }\CommentTok{\# distribution of the mediator}
\end{Highlighting}
\end{Shaded}

\section{Estimate the controlled direct effect}\label{estimate-the-controlled-direct-effect}

We can use the \texttt{ltmle} function to estimate a Controlled Direct Effect
\begin{equation*} \small
  CDE(M=0) = \mathbb{E}\left(Y_{A=2, M=0} \right) - \mathbb{E}\left(Y_{A=0, M=0} \right) = \mathbb{E}\left(Y_{A(1)_1=0, A(1)_2 = 1, M_1 = 0, M_2 = 0} \right) - \mathbb{E}\left(Y_{A(1)_1=0, A(1)_2 = 0, M_1 = 0, M_2 = 0} \right)
\end{equation*}
We will also estimate the Average Total Effect:
\begin{equation*}
  ATE_{A=2 vs A=0} = \mathbb{E}\left(Y_{A=2} \right) - \mathbb{E}\left(Y_{A=0} \right) = \mathbb{E}\left(Y_{A(1)_1=0, A(1)_2 = 1} \right) - \mathbb{E}\left(Y_{A(1)_1=0, A(1)_2 = 0} \right)
\end{equation*}

Before :

\begin{itemize}
\tightlist
\item
  We need to format the censoring variables, using the \texttt{BinoryToCensoring} function which converts binary censoring variables to character vectors of \texttt{censored/uncensored} values.
\item
  We can define a determinist g-function to use with the 3-level exposure and mediator.
\end{itemize}

Note 1: in this example, we let the \texttt{ltmle} function define automatically the variables to include in the Q-formulas and g-formulas.

Note 2: g-formulas should include censoring mechanisms, in addition to the exposure and mediator.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ltmle)}
\NormalTok{df\_ltmle }\OtherTok{\textless{}{-}}\NormalTok{ df2}

\DocumentationTok{\#\# format censoring variables:}
\NormalTok{df\_ltmle}\SpecialCharTok{$}\NormalTok{C1 }\OtherTok{\textless{}{-}} \FunctionTok{BinaryToCensoring}\NormalTok{(}\AttributeTok{is.censored =}\NormalTok{ df\_ltmle}\SpecialCharTok{$}\NormalTok{C1)}
\NormalTok{df\_ltmle}\SpecialCharTok{$}\NormalTok{C2 }\OtherTok{\textless{}{-}} \FunctionTok{BinaryToCensoring}\NormalTok{(}\AttributeTok{is.censored =}\NormalTok{ df\_ltmle}\SpecialCharTok{$}\NormalTok{C2)}

\DocumentationTok{\#\# format the outcome (see the ltmle documation ?ltmle):}
\CommentTok{\# once a Ynode jumps to 1 (e.g. death), all subsequent Ynode values should be 1}
\NormalTok{df\_ltmle}\SpecialCharTok{$}\NormalTok{Y2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(df\_ltmle}\SpecialCharTok{$}\NormalTok{Y1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, df\_ltmle}\SpecialCharTok{$}\NormalTok{Y2) }

\FunctionTok{head}\NormalTok{(df\_ltmle, }\DecValTok{13}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     X L0_1 L0_2 A1_1 A1_2         C1 Y1       L1 M2_1 M2_2         C2 Y2
## 1   1    0    1    0    0 uncensored  0 84.37728    1    0 uncensored  0
## 2   2    1    1    1    0 uncensored  0 56.79832    0    1 uncensored  1
## 3   3    1    1    0    1 uncensored  0 68.84374    1    0   censored NA
## 4   4    1    0    0    0 uncensored  0 78.65583    1    0 uncensored  0
## 5   5    1    1    0    0 uncensored  0 61.33529    1    0 uncensored  0
## 6   6    1    1    0    0 uncensored  0 69.81963    0    1 uncensored  0
## 7   7    0    1    0    0 uncensored  0 42.79730    1    0 uncensored  0
## 8   8    0    1    0    0 uncensored  0 26.72749    1    0 uncensored  0
## 9   9    1    1    1    0 uncensored  0 51.65862    1    0 uncensored  0
## 10 10    0    1    0    0 uncensored  0 29.31751    1    0 uncensored  0
## 11 11    1    0    0    0 uncensored  1       NA   NA   NA       <NA>  1
## 12 12    0    0    0    0 uncensored  0 54.69811    0    0 uncensored  0
## 13 13    0    0    0    1 uncensored  0 36.30073    1    0 uncensored  0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Define an SuperLearner library (choose a various set of learner in practice)}
\NormalTok{SL.library }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"SL.glm"}\NormalTok{, }\StringTok{"SL.mean"}\NormalTok{)}

\DocumentationTok{\#\# Dealing with multicategorical exposures and mediators}
\DocumentationTok{\#\# we can incorporate deterministic knowledge that can be used with the }
\DocumentationTok{\#\# "deterministic.g.function" argument of the ltmle function:}
\NormalTok{det.g }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(data, current.node, nodes) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{names}\NormalTok{(data)[current.node] }\SpecialCharTok{!=} \StringTok{"A1\_2"} \SpecialCharTok{\&}  \FunctionTok{names}\NormalTok{(data)[current.node] }\SpecialCharTok{!=} \StringTok{"M2\_2"}\NormalTok{) \{}
    \FunctionTok{return}\NormalTok{(}\ConstantTok{NULL}\NormalTok{) }\CommentTok{\# for other variables}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{names}\NormalTok{(data)[current.node] }\SpecialCharTok{==} \StringTok{"A1\_2"}\NormalTok{) \{}
\NormalTok{    is.deterministic }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{A1\_1 }\SpecialCharTok{==} \DecValTok{1} \CommentTok{\# if we\textquotesingle{}re regressing A1\_2, }
                                       \CommentTok{\# then: if A1\_1=1 then P(A1\_2 = 1) = 0}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{is.deterministic =}\NormalTok{ is.deterministic, }\AttributeTok{prob1 =} \DecValTok{0}\NormalTok{))}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{names}\NormalTok{(data)[current.node] }\SpecialCharTok{==} \StringTok{"M2\_2"}\NormalTok{) \{}
\NormalTok{    is.deterministic }\OtherTok{\textless{}{-}}\NormalTok{ data}\SpecialCharTok{$}\NormalTok{M2\_1 }\SpecialCharTok{==} \DecValTok{1} \CommentTok{\# if we\textquotesingle{}re regressing M2\_2, }
                                       \CommentTok{\# then: if M2\_1=1 then P(M2\_2 = 1) = 0}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{is.deterministic =}\NormalTok{ is.deterministic, }\AttributeTok{prob1 =} \DecValTok{0}\NormalTok{))}
\NormalTok{  \}}
    \ControlFlowTok{else}\NormalTok{ \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"something went wrong!"}\NormalTok{) }\CommentTok{\# defensive programming}
\NormalTok{  \}}
\NormalTok{\}}

\DocumentationTok{\#\# run the ltmle function}
\NormalTok{CDE\_A2vA0\_M0 }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df\_ltmle,}
                \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"A1\_1"}\NormalTok{, }\StringTok{"A1\_2"}\NormalTok{, }\StringTok{"M2\_1"}\NormalTok{, }\StringTok{"M2\_2"}\NormalTok{), }\CommentTok{\# exposure and mediator}
                \AttributeTok{Cnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"C1"}\NormalTok{, }\StringTok{"C2"}\NormalTok{),}
                \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"L1"}\NormalTok{),}
                \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"Y1"}\NormalTok{, }\StringTok{"Y2"}\NormalTok{),}
                \AttributeTok{survivalOutcome =} \ConstantTok{TRUE}\NormalTok{,}
                \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{\# A1 = 2 \# EY(A=2,M=0)}
                            \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\# M2 = 0 \# EY(A=0,M=0)}
                \AttributeTok{deterministic.g.function =}\NormalTok{ det.g,}
                \AttributeTok{SL.library =}\NormalTok{ SL.library,}
                \AttributeTok{gcomp =} \ConstantTok{FALSE}\NormalTok{,}
                \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Qform not specified, using defaults:
\end{verbatim}

\begin{verbatim}
## formula for Y1:
\end{verbatim}

\begin{verbatim}
## Q.kplus1 ~ X + L0_1 + L0_2 + A1_1 + A1_2
\end{verbatim}

\begin{verbatim}
## formula for Y2:
\end{verbatim}

\begin{verbatim}
## Q.kplus1 ~ X + L0_1 + L0_2 + A1_1 + A1_2 + L1 + M2_1 + M2_2
\end{verbatim}

\begin{verbatim}
## 
\end{verbatim}

\begin{verbatim}
## gform not specified, using defaults:
\end{verbatim}

\begin{verbatim}
## formula for A1_1:
\end{verbatim}

\begin{verbatim}
## A1_1 ~ X + L0_1 + L0_2
\end{verbatim}

\begin{verbatim}
## formula for A1_2:
\end{verbatim}

\begin{verbatim}
## A1_2 ~ X + L0_1 + L0_2 + A1_1
\end{verbatim}

\begin{verbatim}
## formula for C1:
\end{verbatim}

\begin{verbatim}
## C1 ~ X + L0_1 + L0_2 + A1_1 + A1_2
\end{verbatim}

\begin{verbatim}
## formula for M2_1:
\end{verbatim}

\begin{verbatim}
## M2_1 ~ X + L0_1 + L0_2 + A1_1 + A1_2 + L1
\end{verbatim}

\begin{verbatim}
## formula for M2_2:
\end{verbatim}

\begin{verbatim}
## M2_2 ~ X + L0_1 + L0_2 + A1_1 + A1_2 + L1 + M2_1
\end{verbatim}

\begin{verbatim}
## formula for C2:
\end{verbatim}

\begin{verbatim}
## C2 ~ X + L0_1 + L0_2 + A1_1 + A1_2 + L1 + M2_1 + M2_2
\end{verbatim}

\begin{verbatim}
## 
\end{verbatim}

\begin{verbatim}
## Estimate of time to completion: 1 minute
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(CDE\_A2vA0\_M0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  tmle 
## Call:
## ltmle(data = df_ltmle, Anodes = c("A1_1", "A1_2", "M2_1", "M2_2"), 
##     Cnodes = c("C1", "C2"), Lnodes = c("L1"), Ynodes = c("Y1", 
##         "Y2"), survivalOutcome = TRUE, abar = list(c(0, 1, 0, 
##         0), c(0, 0, 0, 0)), deterministic.g.function = det.g, 
##     SL.library = SL.library, gcomp = FALSE, variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  0.4033 
##     Estimated Std Err:  0.033428 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.33778, 0.46882) 
## 
## Control Estimate:
##    Parameter Estimate:  0.15786 
##     Estimated Std Err:  0.02203 
##               p-value:  7.7231e-13 
##     95% Conf Interval: (0.11469, 0.20104) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.24544 
##     Estimated Std Err:  0.040026 
##               p-value:  8.6843e-10 
##     95% Conf Interval: (0.16699, 0.32389) 
## 
## Relative Risk:
##    Parameter Estimate:  2.5547 
##   Est Std Err log(RR):  0.16228 
##               p-value:  7.4749e-09 
##     95% Conf Interval: (1.8587, 3.5114) 
## 
## Odds Ratio:
##    Parameter Estimate:  3.6056 
##   Est Std Err log(OR):  0.21618 
##               p-value:  2.9857e-09 
##     95% Conf Interval: (2.3602, 5.5079)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{CDE\_A2vA0\_M0}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{g}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [[1]]$A1_1
##                  Risk      Coef
## SL.glm_All  0.1828096 0.9600873
## SL.mean_All 0.1839670 0.0399127
## 
## [[1]]$A1_2
##                  Risk       Coef
## SL.glm_All  0.2358587 0.98738181
## SL.mean_All 0.2438133 0.01261819
## 
## [[1]]$C1
##                   Risk      Coef
## SL.glm_All  0.04905206 0.9073443
## SL.mean_All 0.04922034 0.0926557
## 
## [[1]]$M2_1
##                  Risk      Coef
## SL.glm_All  0.1839150 0.2953515
## SL.mean_All 0.1838302 0.7046485
## 
## [[1]]$M2_2
##                  Risk       Coef
## SL.glm_All  0.1302708 0.92939499
## SL.mean_All 0.1376532 0.07060501
## 
## [[1]]$C2
##                   Risk       Coef
## SL.glm_All  0.08307675 0.91616088
## SL.mean_All 0.08385440 0.08383912
## 
## 
## [[2]]
## [[2]]$A1_1
##                  Risk      Coef
## SL.glm_All  0.1828096 0.9600873
## SL.mean_All 0.1839670 0.0399127
## 
## [[2]]$A1_2
##                  Risk       Coef
## SL.glm_All  0.2358587 0.98738181
## SL.mean_All 0.2438133 0.01261819
## 
## [[2]]$C1
##                   Risk      Coef
## SL.glm_All  0.04905206 0.9073443
## SL.mean_All 0.04922034 0.0926557
## 
## [[2]]$M2_1
##                  Risk      Coef
## SL.glm_All  0.1839150 0.2953515
## SL.mean_All 0.1838302 0.7046485
## 
## [[2]]$M2_2
##                  Risk       Coef
## SL.glm_All  0.1302708 0.92939499
## SL.mean_All 0.1376532 0.07060501
## 
## [[2]]$C2
##                   Risk       Coef
## SL.glm_All  0.08307675 0.91616088
## SL.mean_All 0.08385440 0.08383912
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{CDE\_A2vA0\_M0}\SpecialCharTok{$}\NormalTok{fit}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [[1]]$Y1
##                   Risk        Coef
## SL.glm_All  0.06307006 0.994996871
## SL.mean_All 0.06833395 0.005003129
## 
## [[1]]$Y2
##                  Risk       Coef
## SL.glm_All  0.1708663 0.98570313
## SL.mean_All 0.1770992 0.01429687
## 
## 
## [[2]]
## [[2]]$Y1
##                   Risk       Coef
## SL.glm_All  0.09451827 0.98460715
## SL.mean_All 0.09865130 0.01539285
## 
## [[2]]$Y2
##                  Risk       Coef
## SL.glm_All  0.1708663 0.98570313
## SL.mean_All 0.1770992 0.01429687
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# Average total effect}
\DocumentationTok{\#\# we do not need the mediators, but we need the censoring variables}
\DocumentationTok{\#\# (which are considered as exposures)}
\NormalTok{ATE\_A2vA0 }\OtherTok{\textless{}{-}} \FunctionTok{ltmle}\NormalTok{(}\AttributeTok{data =} \FunctionTok{subset}\NormalTok{(df\_ltmle, }\AttributeTok{select =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(M2\_1, M2\_2)),}
                      \AttributeTok{Anodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"A1\_1"}\NormalTok{, }\StringTok{"A1\_2"}\NormalTok{), }\CommentTok{\# exposure and mediator}
                      \AttributeTok{Cnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"C1"}\NormalTok{, }\StringTok{"C2"}\NormalTok{),}
                      \AttributeTok{Lnodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"L1"}\NormalTok{),}
                      \AttributeTok{Ynodes =} \FunctionTok{c}\NormalTok{(}\StringTok{"Y1"}\NormalTok{, }\StringTok{"Y2"}\NormalTok{),}
                      \AttributeTok{survivalOutcome =} \ConstantTok{TRUE}\NormalTok{,}
                      \AttributeTok{abar =} \FunctionTok{list}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{), }\CommentTok{\# A1 = 2 \# EY(A=2)}
                                  \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)), }\CommentTok{\# M2 = 0 \# EY(A=0)}
                      \AttributeTok{deterministic.g.function =}\NormalTok{ det.g,}
                      \AttributeTok{SL.library =}\NormalTok{ SL.library,}
                      \AttributeTok{gcomp =} \ConstantTok{FALSE}\NormalTok{,}
                      \AttributeTok{variance.method =} \StringTok{"ic"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Qform not specified, using defaults:
\end{verbatim}

\begin{verbatim}
## formula for Y1:
\end{verbatim}

\begin{verbatim}
## Q.kplus1 ~ X + L0_1 + L0_2 + A1_1 + A1_2
\end{verbatim}

\begin{verbatim}
## formula for Y2:
\end{verbatim}

\begin{verbatim}
## Q.kplus1 ~ X + L0_1 + L0_2 + A1_1 + A1_2 + L1
\end{verbatim}

\begin{verbatim}
## 
\end{verbatim}

\begin{verbatim}
## gform not specified, using defaults:
\end{verbatim}

\begin{verbatim}
## formula for A1_1:
\end{verbatim}

\begin{verbatim}
## A1_1 ~ X + L0_1 + L0_2
\end{verbatim}

\begin{verbatim}
## formula for A1_2:
\end{verbatim}

\begin{verbatim}
## A1_2 ~ X + L0_1 + L0_2 + A1_1
\end{verbatim}

\begin{verbatim}
## formula for C1:
\end{verbatim}

\begin{verbatim}
## C1 ~ X + L0_1 + L0_2 + A1_1 + A1_2
\end{verbatim}

\begin{verbatim}
## formula for C2:
\end{verbatim}

\begin{verbatim}
## C2 ~ X + L0_1 + L0_2 + A1_1 + A1_2 + L1
\end{verbatim}

\begin{verbatim}
## 
\end{verbatim}

\begin{verbatim}
## Estimate of time to completion: 1 minute
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(ATE\_A2vA0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Estimator:  tmle 
## Call:
## ltmle(data = subset(df_ltmle, select = -c(M2_1, M2_2)), Anodes = c("A1_1", 
##     "A1_2"), Cnodes = c("C1", "C2"), Lnodes = c("L1"), Ynodes = c("Y1", 
##     "Y2"), survivalOutcome = TRUE, abar = list(c(0, 1), c(0, 
##     0)), deterministic.g.function = det.g, SL.library = SL.library, 
##     gcomp = FALSE, variance.method = "ic")
## 
## Treatment Estimate:
##    Parameter Estimate:  0.42858 
##     Estimated Std Err:  0.0080164 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.41287, 0.4443) 
## 
## Control Estimate:
##    Parameter Estimate:  0.22137 
##     Estimated Std Err:  0.0081064 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.20548, 0.23726) 
## 
## Additive Treatment Effect:
##    Parameter Estimate:  0.20721 
##     Estimated Std Err:  0.01138 
##               p-value:  <2e-16 
##     95% Conf Interval: (0.18491, 0.22952) 
## 
## Relative Risk:
##    Parameter Estimate:  1.936 
##   Est Std Err log(RR):  0.041059 
##               p-value:  <2e-16 
##     95% Conf Interval: (1.7863, 2.0983) 
## 
## Odds Ratio:
##    Parameter Estimate:  2.6381 
##   Est Std Err log(OR):  0.057203 
##               p-value:  <2e-16 
##     95% Conf Interval: (2.3583, 2.9511)
\end{verbatim}

In this example,

\begin{itemize}
\tightlist
\item
  the g-computation algorithm estimates the \(\bar{Q}\) function among the uncensored participants (and the censoring mechanism is not taken into account by g-computation). The estimation can be biased because of attrition;
\item
  however, the censoring mechanism is still taken into account with the IPTW estimator (similarly to an estimation by Inverse Probability of Censoring Weighting, \emph{IPCW}).
\end{itemize}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-Diaz2020}
Díaz, I, N S Hejazi, K E Rudolph, and M J van Der Laan. 2020. {``{Nonparametric efficient causal mediation with intermediate confounders}.''} \emph{Biometrika} 108 (3): 627--41. \url{https://doi.org/10.1093/biomet/asaa085}.

\bibitem[\citeproctext]{ref-Diaz2023}
Díaz, Iván, Nicholas Williams, and Kara E Rudolph. 2023. {``{Efficient and flexible mediation analysis with time-varying mediators, treatments, and confounders}.''} \emph{Journal of Causal Inference} 11 (1): 20220077. \url{https://doi.org/10.1515/jci-2022-0077}.

\bibitem[\citeproctext]{ref-Hejazi2022}
Hejazi, Nima S., Kara E. Rudolph, and Iván Díaz. 2022. {```Medoutcon`: Nonparametric Efficient Causal Mediation Analysis with Machine Learning in `r`.''} \emph{Journal of Open Source Software} 7 (69): 3979. \url{https://doi.org/10.21105/joss.03979}.

\bibitem[\citeproctext]{ref-vanderlaan_book2011}
Laan, Mark J. van der, and Sherri Rose. 2011. \emph{Targeted Learning: Causal Inference for Observational and Experimental Data.} 1st ed. Springer Series in Statistics. New York, NY: Springer.

\bibitem[\citeproctext]{ref-vanderweele2009}
VanderWeele, Tyler J. 2009. {``Marginal Structural Models for the Estimation of Direct and Indirect Effects.''} \emph{Epidemiology} 20: 18--26.

\end{CSLReferences}

\end{document}
